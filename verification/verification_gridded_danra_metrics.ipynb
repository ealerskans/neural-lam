{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de5d8017",
   "metadata": {},
   "source": [
    "##  Gridded Model Verification\n",
    "\n",
    "This script verifies output from a ML-based foundation model versus a\n",
    "traditional NWP system for the atmospheric system. The defaults set at the top of\n",
    "this script are tailored to the Alps-Clariden HPC system at CSCS.\n",
    "- The NWP-model is called DANRA-forecasts and is initialised with the analysis. Only surface level data is available, and up to 18 h lead time.\n",
    "- The ML-model is called Neural-LAM and is initialised from the DANRA reanalysis.\n",
    "- The Ground Truth is the same deterministic DANRA reanalysis as was used to train the ML-model.\n",
    "- The boundary data for both models is IFS HRES from ECMWF, where the NWP-model got 6 hourly boundary updates (?) and the ML model 12 hourly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0311b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import dask\n",
    "import matplotlib.pyplot as plt\n",
    "from dask.distributed import LocalCluster, Client\n",
    "import numpy as np\n",
    "from dask.diagnostics import ProgressBar\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from pysteps.verification.salscores import sal  # requires scikit-image\n",
    "from scipy.stats import kurtosis, skew, wasserstein_distance\n",
    "from scores.categorical import ThresholdEventOperator as TEO\n",
    "from scores.continuous import (\n",
    "    mae,\n",
    "    mean_error,\n",
    "    mse,\n",
    "    rmse,\n",
    ")\n",
    "from scores.continuous.correlation import pearsonr\n",
    "from scores.spatial import fss_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a806b47",
   "metadata": {},
   "source": [
    "**--------> Enter all your user settings in the cell below. <--------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf621a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFAULTS ###\n",
    "# This config will be applied to the data before any plotting. The data will be\n",
    "# sliced and indexed according to the values in this config.The whole analysis and\n",
    "# plotting will be done on the reduced data.\n",
    "\n",
    "# IF YOUR DATA HAS DIFFERENT DIMENSIONS OR NAMES, PLEASE ADJUST THE CELLS BELOW\n",
    "# MAKE SURE THE XARRAY DATASETS LOOK OKAY BEFORE RUNNING CHAPTER 1-4\n",
    "\n",
    "# This path should point to the data that was used to train the model (default is mdp-datastore)\n",
    "PATH_GROUND_TRUTH = \"danra_test_gt.zarr\"\n",
    "# This path should point to the NWP forecast data in zarr format\n",
    "PATH_NWP = \"danra_test_nwp_forecasts.zarr\"\n",
    "# This path should point to the ML forecast data in zarr format (e.g. produced by neural-lam in `eval` mode)\n",
    "PATH_ML = \"48h_eval_test_7deg_rect_hi4_2867.zarr\"\n",
    "# This path should point to the boundary data in zarr format (default is MDP-datastore)\n",
    "PATH_BOUNDARY = \"ifs_test_boundary.zarr\"\n",
    "\n",
    "# elapsed forecast duration in steps for the forecast - [0] refers to the first forecast step at t+1\n",
    "# this should be a list of integers\n",
    "ELAPSED_FORECAST_DURATION = list(range(16))\n",
    "ELAPSED_FORECAST_DURATION_SHORT = list(range(6)) # 18 h, matching NWP forecasts\n",
    "ELAPSED_FORECAST_DURATION_PLOT = [1,3,5] # ELS to plot\n",
    "ELAPSED_FORECAST_DURATION_VERTICAL = [0, 3, 7, 11, 15] # For vertical profiles\n",
    "\n",
    "# Select specific start_times for the forecast. This is the start and end of\n",
    "# a slice in xarray. The start_time is included, the end_time is excluded.\n",
    "# This should be a list of two strings in the format \"YYYY-MM-DDTHH:MM:SS\"\n",
    "# Should be handy to evaluate certain dates, e.g. for a case study of a storm\n",
    "#START_TIMES = [\"2020-02-07T00:00:00\", \"2020-02-10T00:00:00\"] # 7 init times, ~1% of full year\n",
    "START_TIMES = [\"2019-10-30T00:00\", \"2020-10-23T12:00\"] # Full year, 720 init times\n",
    "\n",
    "# Select specific plot times for the forecast (will be used to create maps for all variables)\n",
    "# This only affect chapter one with the plotting of the maps\n",
    "# Map creation takes a lot of time so this is limited to a single time step\n",
    "# Simply rerun these cells and chapter one for more time steps\n",
    "PLOT_TIME = \"2020-02-09T12:00:00\"\n",
    "\n",
    "# Selection spatial grid in projection\n",
    "# This is used to slice the data to a specific region\n",
    "# This is in projection of the ground truth data\n",
    "# The default is the whole domain [None, None]\n",
    "X = [None, None]\n",
    "Y = [None, None]\n",
    "# Alternative X, Y for Denmark cutout\n",
    "# X = [-1080000, -600000]\n",
    "# Y = [-160000,220000]\n",
    "\n",
    "# Map projection settings for plotting\n",
    "# This is the projection of the ground truth data\n",
    "PROJECTION = ccrs.LambertConformal(\n",
    "    central_longitude=25.0,\n",
    "    central_latitude=56.7,\n",
    "    standard_parallels=[56.7, 56.7],\n",
    "    globe=ccrs.Globe(\n",
    "        semimajor_axis=6367470.0,\n",
    "        semiminor_axis=6367470.0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Define how variables map between different data sources\n",
    "\n",
    "# Define here which of the variables are available in the ground truth data\n",
    "# The keys are the names of the variables in the ground truth data\n",
    "# The values are the conventional names, used in this notebook\n",
    "VARIABLES_GROUND_TRUTH = {\n",
    "    # Surface and near-surface variables\n",
    "    \"t2m\": \"temperature_2m\",\n",
    "    \"u10m\": \"wind_u_10m\",\n",
    "    \"v10m\": \"wind_v_10m\",\n",
    "    #\"pres_seasurface\": \"pressure_sea_level\",\n",
    "    #\"pres0m\": \"surface_pressure\",\n",
    "    #\"swavr0m\": \"surface_net_shortwave_radiation\",\n",
    "    #\"lwavr0m\": \"surface_net_longwave_radiation\",\n",
    "    # Upper air variables - U component\n",
    "    # \"u100\": \"wind_u_100hPa\",\n",
    "    #\"u200\": \"wind_u_200hPa\",\n",
    "    # \"u400\": \"wind_u_400hPa\",\n",
    "    # \"u600\": \"wind_u_600hPa\",\n",
    "    #\"u700\": \"wind_u_700hPa\",\n",
    "    # \"u850\": \"wind_u_850hPa\",\n",
    "    # \"u925\": \"wind_u_925hPa\",\n",
    "    # \"u1000\": \"wind_u_1000hPa\",\n",
    "    # Upper air variables - V component\n",
    "    # \"v100\": \"wind_v_100hPa\",\n",
    "    #\"v200\": \"wind_v_200hPa\",\n",
    "    # \"v400\": \"wind_v_400hPa\",\n",
    "    # \"v600\": \"wind_v_600hPa\",\n",
    "    #\"v700\": \"wind_v_700hPa\",\n",
    "    # \"v850\": \"wind_v_850hPa\",\n",
    "    # \"v925\": \"wind_v_925hPa\",\n",
    "    # \"v1000\": \"wind_v_1000hPa\",\n",
    "    # Upper air variables - Pressure\n",
    "    # \"z100\": \"geopotential_100hPa\",\n",
    "    # \"z200\": \"geopotential_200hPa\",\n",
    "    # \"z400\": \"geopotential_400hPa\",\n",
    "    # \"z600\": \"geopotential_600hPa\",\n",
    "    #\"z700\": \"geopotential_700hPa\",\n",
    "    # \"z850\": \"geopotential_850hPa\",\n",
    "    # \"z925\": \"geopotential_925hPa\",\n",
    "    # \"z1000\": \"geopotential_1000hPa\",\n",
    "    # Upper air variables - Temperature\n",
    "    # \"t100\": \"temperature_100hPa\",\n",
    "    # \"t200\": \"temperature_200hPa\",\n",
    "    # \"t400\": \"temperature_400hPa\",\n",
    "    # \"t600\": \"temperature_600hPa\",\n",
    "    #\"t700\": \"temperature_700hPa\",\n",
    "    # \"t850\": \"temperature_850hPa\",\n",
    "    # \"t925\": \"temperature_925hPa\",\n",
    "    # \"t1000\": \"temperature_1000hPa\",\n",
    "    # Upper air variables - Relative Humidity\n",
    "    # \"r100\": \"relative_humidity_100hPa\",\n",
    "    #\"r200\": \"relative_humidity_200hPa\",\n",
    "    # \"r400\": \"relative_humidity_400hPa\",\n",
    "    # \"r600\": \"relative_humidity_600hPa\",\n",
    "    #\"r700\": \"relative_humidity_700hPa\",\n",
    "    # \"r850\": \"relative_humidity_850hPa\",\n",
    "    # \"r925\": \"relative_humidity_925hPa\",\n",
    "    # \"r1000\": \"relative_humidity_1000hPa\",\n",
    "    # Upper air variables - Vertical velocity\n",
    "    # \"tw100\": \"vertical_velocity_100hPa\",\n",
    "    #\"tw200\": \"vertical_velocity_200hPa\",\n",
    "    # \"tw400\": \"vertical_velocity_400hPa\",\n",
    "    # \"tw600\": \"vertical_velocity_600hPa\",\n",
    "    #\"tw700\": \"vertical_velocity_700hPa\",\n",
    "    # \"tw850\": \"vertical_velocity_850hPa\",\n",
    "    # \"tw925\": \"vertical_velocity_925hPa\",\n",
    "    # \"tw1000\": \"vertical_velocity_1000hPa\",\n",
    "}\n",
    "\n",
    "REQUIRED_LEVELS = [\n",
    "    100,\n",
    "    200,\n",
    "    400,\n",
    "    600,\n",
    "    700,\n",
    "    850,\n",
    "    925,\n",
    "    1000,\n",
    "]\n",
    "\n",
    "# Since the default ground_truth is the datastore that was used for model training\n",
    "# the variables are identical to the VARIABLES_GROUND_TRUTH\n",
    "VARIABLES_ML = VARIABLES_GROUND_TRUTH\n",
    "\n",
    "# For the NWP-Forecast only a limited set of variables is available\n",
    "# These variables are mapped to the same conventional names\n",
    "# The script is flexible and will only calculate the NWP-metrics for the variables that are available\n",
    "# The script will not break if some of the variables are not available\n",
    "VARIABLES_NWP = {\n",
    "    \"t2m\": \"temperature_2m\",\n",
    "    \"u10m\": \"wind_u_10m\",\n",
    "    \"v10m\": \"wind_v_10m\",\n",
    "    \"pres_seasurface\": \"seasurface_pressure\",\n",
    "}\n",
    "\n",
    "# These variables are only used for chapter 1, the mapplots.\n",
    "# They will be plotted for the ground truth, NWP and ML\n",
    "VARIABLES_BOUNDARY = {\n",
    "    # Surface and near-surface variables\n",
    "    \"mean_sea_level_pressure\": \"pressure_sea_level\",\n",
    "    \"2m_temperature\": \"temperature_2m\",\n",
    "    \"10m_u_component_of_wind\": \"wind_u_10m\",\n",
    "    \"10m_v_component_of_wind\": \"wind_v_10m\",\n",
    "    \"surface_pressure\": \"surface_pressure\",\n",
    "    # Upper air variables - U component\n",
    "    \"u_component_of_wind100\": \"wind_u_100hPa\",\n",
    "    \"u_component_of_wind200\": \"wind_u_200hPa\",\n",
    "    \"u_component_of_wind400\": \"wind_u_400hPa\",\n",
    "    \"u_component_of_wind600\": \"wind_u_600hPa\",\n",
    "    \"u_component_of_wind700\": \"wind_u_700hPa\",\n",
    "    \"u_component_of_wind850\": \"wind_u_850hPa\",\n",
    "    \"u_component_of_wind925\": \"wind_u_925hPa\",\n",
    "    \"u_component_of_wind1000\": \"wind_u_1000hPa\",\n",
    "    # Upper air variables - V component\n",
    "    \"v_component_of_wind100\": \"wind_v_100hPa\",\n",
    "    \"v_component_of_wind200\": \"wind_v_200hPa\",\n",
    "    \"v_component_of_wind400\": \"wind_v_400hPa\",\n",
    "    \"v_component_of_wind600\": \"wind_v_600hPa\",\n",
    "    \"v_component_of_wind700\": \"wind_v_700hPa\",\n",
    "    \"v_component_of_wind850\": \"wind_v_850hPa\",\n",
    "    \"v_component_of_wind925\": \"wind_v_925hPa\",\n",
    "    \"v_component_of_wind1000\": \"wind_v_1000hPa\",\n",
    "    # Upper air variables - Temperature\n",
    "    \"temperature100\": \"temperature_100hPa\",\n",
    "    \"temperature200\": \"temperature_200hPa\",\n",
    "    \"temperature400\": \"temperature_400hPa\",\n",
    "    \"temperature600\": \"temperature_600hPa\",\n",
    "    \"temperature700\": \"temperature_700hPa\",\n",
    "    \"temperature850\": \"temperature_850hPa\",\n",
    "    \"temperature925\": \"temperature_925hPa\",\n",
    "    \"temperature1000\": \"temperature_1000hPa\",\n",
    "    # Upper air variables - Vertical velocity\n",
    "    \"vertical_velocity100\": \"vertical_velocity_100hPa\",\n",
    "    \"vertical_velocity200\": \"vertical_velocity_200hPa\",\n",
    "    \"vertical_velocity400\": \"vertical_velocity_400hPa\",\n",
    "    \"vertical_velocity600\": \"vertical_velocity_600hPa\",\n",
    "    \"vertical_velocity700\": \"vertical_velocity_700hPa\",\n",
    "    \"vertical_velocity850\": \"vertical_velocity_850hPa\",\n",
    "    \"vertical_velocity925\": \"vertical_velocity_925hPa\",\n",
    "    \"vertical_velocity1000\": \"vertical_velocity_1000hPa\",\n",
    "    # Upper air variables - Geopotential\n",
    "    \"geopotential100\": \"geopotential_100hPa\",\n",
    "    \"geopotential200\": \"geopotential_200hPa\",\n",
    "    \"geopotential400\": \"geopotential_400hPa\",\n",
    "    \"geopotential600\": \"geopotential_600hPa\",\n",
    "    \"geopotential700\": \"geopotential_700hPa\",\n",
    "    \"geopotential850\": \"geopotential_850hPa\",\n",
    "    \"geopotential925\": \"geopotential_925hPa\",\n",
    "    \"geopotential1000\": \"geopotential_1000hPa\",\n",
    "}\n",
    "\n",
    "\n",
    "# These variables will be used as `basename` for the vertical profiles.\n",
    "# Since the input of the zarr archives is expected to have data vars that are 2D in space\n",
    "# we need some base_name prefix to create the 3D variables\n",
    "VARIABLES_3D = [\n",
    "    \"wind_u\",\n",
    "    \"wind_v\",\n",
    "    \"geopotential\",\n",
    "    \"temperature\",\n",
    "    \"relative_humidity\",\n",
    "    \"vertical_velocity\",\n",
    "]\n",
    "\n",
    "# Add units dictionary after the imports\n",
    "# units from zarr archives are not reliable and should rather be defined here\n",
    "VARIABLE_UNITS = {\n",
    "    # Surface and near-surface variables\n",
    "    \"temperature_2m\": \"K\",\n",
    "    \"wind_u_10m\": \"m/s\",\n",
    "    \"wind_v_10m\": \"m/s\",\n",
    "    \"pressure_sea_level\": \"Pa\",\n",
    "    \"surface_pressure\": \"Pa\",\n",
    "    \"precipitation\": \"mm/h\",\n",
    "    #\"surface_sensible_heat_flux\": \"W/m²\",\n",
    "    \"surface_net_shortwave_radiation\": \"W/m²\",\n",
    "    \"surface_net_longwave_radiation\": \"W/m²\",\n",
    "    # Upper air variables\n",
    "    \"wind_u_level\": \"m/s\",\n",
    "    \"wind_v_level\": \"m/s\",\n",
    "    \"geopotential_level\": \"m²/s²\",\n",
    "    \"temperature_level\": \"K\",\n",
    "    \"relative_humidity_level\": \"%\",\n",
    "    \"vertical_velocity_level\": \"Pa/s\",\n",
    "}\n",
    "\n",
    "# Define Thresholds for the ETS metric (Equitable Threat Score)\n",
    "# These are calculated for wind and precipitation if available\n",
    "# The score creates contingency tables for different thresholds\n",
    "# The ETS is calculated for each threshold and the results are plotted\n",
    "# The default thresholds are [0.1, 1, 5] for precipitation and [2.5, 5, 10] for wind\n",
    "THRESHOLDS_PRECIPITATION = [0.1, 1, 5]  # mm/h\n",
    "THRESHOLDS_WIND = [2.5, 5, 10]  # m/s\n",
    "\n",
    "# Define the metrics to compute for the verification\n",
    "# Some additional verifications will always be computed if the repsective vars\n",
    "# are available in the data\n",
    "METRICS = [\n",
    "    # \"MAE\",\n",
    "    \"RMSE\",\n",
    "    # \"MSE\",\n",
    "    \"ME\",\n",
    "    \"STDEV_ERR\",\n",
    "    #\"RelativeMAE\",\n",
    "    # \"RelativeRMSE\",\n",
    "    # \"PearsonR\",\n",
    "    # \"Wasserstein\",\n",
    "]\n",
    "\n",
    "# This setting is relevant for the mapplots in chapter 1\n",
    "# Higher levels of ZOOM will zoom in on the map, cropping the boundary\n",
    "BORDER_WIDTH = 300000 # in m\n",
    "ZOOM = 1  # Unused\n",
    "\n",
    "# For some chapters a random seed is required to reproduce the results\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# The DPI used in all plots in the notebook, export to pdf will always be 300 DPI\n",
    "DPI = 100\n",
    "\n",
    "# Subsample the data for faster plotting, 0.1 refers to 10% of the ml/nwp data\n",
    "# sampled along the start_time, x and y dimensions. If you calculate the FSS\n",
    "# metrics you would want to limit subsampling to the time-dimensions! There is a\n",
    "# trade-off between speed and accuracy, that each user has to find.\n",
    "SUBSAMPLE_FRACTION = 1.0\n",
    "\n",
    "# If the data should be loaded into memory. Makes following calculations faster\n",
    "# but requires enough memory to hold the data.\n",
    "PRECOMPUTE_DATA = False\n",
    "\n",
    "# Subsample the data for FSS threshold calculation, 1e7 refers to the number of elements\n",
    "# This is not critical, as it is only used to calculate the 90% threshold\n",
    "# for the FSS based on the ground truth data\n",
    "SUBSAMPLE_FSS_THRESHOLD = 1e7\n",
    "\n",
    "# Takes a long time, but if you see NaN in your output, you can set this to True\n",
    "# This will check if there are any missing values in the data further below\n",
    "# THIS NOTEBOOK WILL ONLY WORK RELIABLY IF THERE ARE NO MISSING VALUES\n",
    "# If there are missing values, you have to interpolate them or remove them\n",
    "CHECK_MISSING = False\n",
    "\n",
    "# Font sizes for consistent plotting (different fig-sizes wil require different font sizes)\n",
    "FONT_SIZES = {\n",
    "    \"axes\": 24,  # Axis labels and titles\n",
    "    \"ticks\": 24,  # Tick labels\n",
    "    \"legend\": 22,  # Legend text\n",
    "    \"cbar\": 24,  # Colorbar labels\n",
    "    \"suptitle\": 24,  # Figure suptitle\n",
    "    \"title\": 24,  # Axes titles\n",
    "    \"stats\": 22,  # Statistics text in plots\n",
    "}\n",
    "\n",
    "DEBUG = False\n",
    "if DEBUG:\n",
    "    # This path should point to the data that was used to train the model (default is mdp-datastore)\n",
    "    # PATH_GROUND_TRUTH = \"danra_test_gt.zarr\"\n",
    "    PATH_GROUND_TRUTH = \"danra_ex_fc/danra_gt.zarr\"\n",
    "    # This path should point to the NWP forecast data in zarr format\n",
    "    # PATH_NWP = \"danra_test_nwp_forecasts.zarr\"\n",
    "    PATH_NWP = \"danra_ex_fc/danra_nwp_ex_forecasts.zarr\"\n",
    "    # This path should point to the ML forecast data in zarr format (e.g. produced by neural-lam in `eval` mode)\n",
    "    # PATH_ML = \"48h_eval_test_7deg_rect_hi4_2867.zarr\"\n",
    "    PATH_ML = \"danra_ex_fc/danra_ml_ex_forecasts.zarr\"\n",
    "    # This path should point to the boundary data in zarr format (default is MDP-datastore)\n",
    "    # PATH_BOUNDARY = \"ifs_test_boundary.zarr\"\n",
    "    PATH_BOUNDARY = \"danra_ex_fc/danra_ifs_boundary.zarr\"\n",
    "\n",
    "    START_TIMES = [\"2020-01-02T00:00\", \"2020-01-04T00:00\"]\n",
    "    PLOT_TIME = \"2020-01-02T00:00:00\"\n",
    "\n",
    "    VARIABLES_GROUND_TRUTH = {\n",
    "        # Surface and near-surface variables\n",
    "        \"t2m\": \"temperature_2m\",\n",
    "        \"u10m\": \"wind_u_10m\",\n",
    "        \"v10m\": \"wind_v_10m\",\n",
    "    }\n",
    "    VARIABLES_ML = VARIABLES_GROUND_TRUTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b2e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for plots and tables\n",
    "Path(\"plots\").mkdir(exist_ok=True)\n",
    "Path(\"tables\").mkdir(exist_ok=True)\n",
    "\n",
    "# Colorblind-friendly color palette\n",
    "COLORS = {\n",
    "    \"gt\": \"#000000\",  # Black\n",
    "    \"ml\": \"#E69F00\",  # Orange\n",
    "    \"nwp\": \"#56B4E9\",  # Light blue\n",
    "    \"per\": \"#CC79A7\",  # Pink\n",
    "}\n",
    "\n",
    "# Line styles and markers for accessibility\n",
    "LINE_STYLES = {\n",
    "    \"gt\": (\"solid\", \"o\"),\n",
    "    \"ml\": (\"dashed\", \"s\"),\n",
    "    \"nwp\": (\"dotted\", \"^\"),\n",
    "    \"per\": (\"dashdot\", \"v\"),\n",
    "}\n",
    "\n",
    "# Set global font sizes\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": FONT_SIZES[\"axes\"],\n",
    "    \"axes.titlesize\": FONT_SIZES[\"axes\"],\n",
    "    \"axes.labelsize\": FONT_SIZES[\"axes\"],\n",
    "    \"xtick.labelsize\": FONT_SIZES[\"ticks\"],\n",
    "    \"ytick.labelsize\": FONT_SIZES[\"ticks\"],\n",
    "    \"legend.fontsize\": FONT_SIZES[\"legend\"],\n",
    "    \"figure.titlesize\": FONT_SIZES[\"suptitle\"],\n",
    "})\n",
    "\n",
    "# Colorblind-friendly colormap for 2D plots\n",
    "COLORMAP = \"viridis\"\n",
    "\n",
    "# First, collect all the base variables and units we need to extend\n",
    "base_level_vars = {}\n",
    "for base_var, unit in VARIABLE_UNITS.items():\n",
    "    if \"_level\" in base_var:\n",
    "        base_level_vars[base_var] = unit\n",
    "\n",
    "# Then create the level-specific entries\n",
    "for level in REQUIRED_LEVELS:\n",
    "    for base_var, unit in base_level_vars.items():\n",
    "        VARIABLE_UNITS[f\"{base_var[:-len('_level')]}_{level}hPa\"] = unit\n",
    "print(f\"All units: {VARIABLE_UNITS}\")\n",
    "\n",
    "\n",
    "def save_plot(fig, name, time=None, remove_title=True, dpi=300):\n",
    "    \"\"\"Helper function to save plots consistently\n",
    "\n",
    "    Args:\n",
    "        fig: matplotlib figure object\n",
    "        name (str): base name for the plot file\n",
    "        time (datetime, optional): timestamp to append to filename\n",
    "        remove_title (bool): remove suptitle/title hierarchically if True\n",
    "        dpi (int): resolution for the saved figure, defaults to 300\n",
    "    \"\"\"\n",
    "    if time is not None:\n",
    "        name = f\"{name}_{time.dt.strftime('%Y%m%d_%H').values}\"\n",
    "\n",
    "    # Sanitize filename by replacing problematic characters\n",
    "    safe_name = name.replace(\"/\", \"_per_\")\n",
    "\n",
    "    # Normalize the path and ensure plots directory exists\n",
    "    plot_dir = Path(\"plots\")\n",
    "    plot_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Remove titles if requested\n",
    "    if remove_title:\n",
    "        if hasattr(fig, \"texts\") and fig.texts:  # Check for suptitle\n",
    "            fig.suptitle(\"\")\n",
    "        ax = fig.gca()\n",
    "        if ax.get_title():\n",
    "            ax.set_title(\"\")\n",
    "\n",
    "    pdf_path = plot_dir / f\"{safe_name}.pdf\"\n",
    "    fig.savefig(pdf_path, bbox_inches=\"tight\", dpi=dpi)\n",
    "\n",
    "\n",
    "def export_table(df, name, caption=\"\"):\n",
    "    \"\"\"Helper function to export tables consistently\"\"\"\n",
    "    # Export to LaTeX with caption\n",
    "    latex_str = df.to_latex(\n",
    "        float_format=\"%.4f\", caption=caption, label=f\"tab:{name}\"\n",
    "    )\n",
    "    with open(f\"tables/{name}.tex\", \"w\") as f:\n",
    "        f.write(latex_str)\n",
    "\n",
    "    # Export to CSV\n",
    "    df.to_csv(f\"tables/{name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ebba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ml = xr.open_zarr(PATH_ML)\n",
    "ds_ml = ds_ml.sel(state_feature=list(VARIABLES_ML.keys()))\n",
    "ds_ml = ds_ml.sel(y=slice(*Y), x=slice(*X))\n",
    "ds_ml = ds_ml.sel(start_time=slice(*START_TIMES))\n",
    "for feature in ds_ml.state_feature.values:\n",
    "    ds_ml[VARIABLES_ML[feature]] = ds_ml[\"state\"].sel(state_feature=feature)\n",
    "forecast_times = (\n",
    "    ds_ml.start_time.values[:, None] + ds_ml.elapsed_forecast_duration.values\n",
    ")\n",
    "ds_ml = ds_ml.assign_coords(\n",
    "    forecast_time=(\n",
    "        (\"start_time\", \"elapsed_forecast_duration\"),\n",
    "        forecast_times,\n",
    "    )\n",
    ")\n",
    "ds_ml = ds_ml.drop_vars([\"state\", \"state_feature\", \"time\"])\n",
    "ds_ml = ds_ml.transpose(\"start_time\", \"elapsed_forecast_duration\", \"x\", \"y\")\n",
    "ds_ml = ds_ml[\n",
    "    [\n",
    "        \"start_time\",\n",
    "        \"elapsed_forecast_duration\",\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        *VARIABLES_ML.values(),\n",
    "    ]\n",
    "]\n",
    "ds_ml = ds_ml.isel(elapsed_forecast_duration=ELAPSED_FORECAST_DURATION)\n",
    "\n",
    "ds_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf42e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_gt = xr.open_zarr(PATH_GROUND_TRUTH)\n",
    "ds_gt = ds_gt.set_index(grid_index=[\"y\", \"x\"]).unstack(\"grid_index\")\n",
    "ds_gt = ds_gt.sel(y=slice(*Y), x=slice(*X))\n",
    "ds_gt = ds_gt.sel(state_feature=list(VARIABLES_ML.keys()))\n",
    "ds_gt = ds_gt.sel(split_name=\"test\").drop_dims([\n",
    "    \"forcing_feature\",\n",
    "    \"static_feature\",\n",
    "    \"split_part\",\n",
    "])\n",
    "for feature in ds_gt.state_feature.values:\n",
    "    ds_gt[VARIABLES_ML[feature]] = ds_gt[\"state\"].sel(state_feature=feature)\n",
    "ds_gt = ds_gt.drop_vars([\n",
    "    \"state\",\n",
    "    \"state_feature\",\n",
    "    \"state_feature_units\",\n",
    "    \"state_feature_long_name\",\n",
    "    \"state_feature_source_dataset\",\n",
    "    \"state__train__diff_mean\",\n",
    "    \"state__train__diff_std\",\n",
    "    \"state__train__mean\",\n",
    "    \"state__train__std\",\n",
    "])\n",
    "ds_gt = ds_gt.transpose(\"time\", \"x\", \"y\")\n",
    "ds_gt = ds_gt[\n",
    "    [\n",
    "        \"time\",\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        *VARIABLES_GROUND_TRUTH.values(),\n",
    "    ]\n",
    "]\n",
    "time_subset = np.concatenate((ds_ml.forecast_time.values.flatten(), ds_ml.start_time.values.flatten()))\n",
    "ds_gt = ds_gt.sel(time=np.unique(time_subset))\n",
    "ds_gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fa285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_nwp = xr.open_zarr(PATH_NWP)\n",
    "ds_nwp = ds_nwp.sel(y=slice(*Y), x=slice(*X), analysis_time=slice(*START_TIMES))\n",
    "ds_nwp = ds_nwp[VARIABLES_NWP.keys()].rename(VARIABLES_NWP)\n",
    "ds_nwp = ds_nwp.rename_dims({\n",
    "    \"analysis_time\": \"start_time\",\n",
    "})\n",
    "ds_nwp = ds_nwp.rename_vars({\n",
    "    \"analysis_time\": \"start_time\",\n",
    "})\n",
    "forecast_times = (\n",
    "    ds_nwp.start_time.values[:, None] + ds_nwp.elapsed_forecast_duration.values\n",
    ")\n",
    "ds_nwp = ds_nwp.assign_coords(\n",
    "    forecast_time=(\n",
    "        (\"start_time\", \"elapsed_forecast_duration\"),\n",
    "        forecast_times,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Do not need these, remove so no issues later\n",
    "ds_nwp = ds_nwp.drop([\"time\"])\n",
    "\n",
    "# The NWP data starts at elapsed forecast duration 0 = start_time\n",
    "ds_nwp = ds_nwp.isel(\n",
    "    elapsed_forecast_duration=ELAPSED_FORECAST_DURATION_SHORT\n",
    ")\n",
    "\n",
    "ds_nwp = ds_nwp.transpose(\"start_time\", \"elapsed_forecast_duration\", \"x\", \"y\")\n",
    "ds_nwp = ds_nwp[\n",
    "    [\n",
    "        \"start_time\",\n",
    "        \"elapsed_forecast_duration\",\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        *VARIABLES_NWP.values(),\n",
    "    ]\n",
    "]\n",
    "\n",
    "ds_nwp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46114d2",
   "metadata": {},
   "source": [
    "Check for missing data in any of the variables. If you have missing data, you need to handle it before running the verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648b77c2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if CHECK_MISSING:\n",
    "    missing_counts = dask.compute(\n",
    "        {var: ds_gt[var].isnull().sum().values for var in ds_gt.data_vars},\n",
    "        {var: ds_nwp[var].isnull().sum().values for var in ds_nwp.data_vars},\n",
    "        {var: ds_ml[var].isnull().sum().values for var in ds_ml.data_vars},\n",
    "    )\n",
    "    # Unpack results\n",
    "    gt_missing, nwp_missing, ml_missing = missing_counts\n",
    "\n",
    "    # Print results\n",
    "    print(\"Ground Truth\")\n",
    "    for var, count in gt_missing.items():\n",
    "        print(f\"{var}: {count} missing values\")\n",
    "\n",
    "    print(\"\\nNWP Model\")\n",
    "    for var, count in nwp_missing.items():\n",
    "        print(f\"{var}: {count} missing values\")\n",
    "\n",
    "    print(\"\\nML Model\")\n",
    "    for var, count in ml_missing.items():\n",
    "        print(f\"{var}: {count} missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b36ff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ds_gt.sizes[\"x\"] == ds_ml.sizes[\"x\"]\n",
    "assert ds_gt.sizes[\"x\"] == ds_nwp.sizes[\"x\"]\n",
    "assert ds_gt.sizes[\"y\"] == ds_ml.sizes[\"y\"]\n",
    "assert ds_gt.sizes[\"y\"] == ds_nwp.sizes[\"y\"]\n",
    "#assert ds_gt.sizes[\"time\"] == len(\n",
    "#    np.unique(ds_ml.forecast_time.values.flatten())\n",
    "#)\n",
    "# Since nwp has less lead times below might not hold\n",
    "#assert ds_gt.sizes[\"time\"] == len(\n",
    "#    np.unique(ds_nwp.forecast_time.values.flatten())\n",
    "#)\n",
    "\n",
    "# Generate random indices for each dimension\n",
    "rng = np.random.RandomState(RANDOM_SEED)\n",
    "sampled_start_time_indices = np.sort(\n",
    "    rng.choice(\n",
    "        len(ds_ml.start_time),\n",
    "        size=int(len(ds_ml.start_time) * SUBSAMPLE_FRACTION),\n",
    "        replace=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "# with (\n",
    "#     LocalCluster(\n",
    "#         n_workers=4,\n",
    "#         threads_per_worker=16,\n",
    "#         memory_limit=\"96GB\",\n",
    "#         local_directory=\"/iopsstor/scratch/cscs/sadamov\",  # Use fast local storage for spilling\n",
    "#         dashboard_address=None,\n",
    "#     ) as cluster\n",
    "# ):\n",
    "#     with Client(cluster) as client:\n",
    "ds_ml_sampled = ds_ml.isel(start_time=sampled_start_time_indices)\n",
    "ds_nwp_sampled = ds_nwp.isel(start_time=sampled_start_time_indices)\n",
    "ds_gt_sampled = ds_gt.sel(time=ds_ml_sampled.forecast_time)\n",
    "if PRECOMPUTE_DATA:\n",
    "    with ProgressBar():\n",
    "        print(\"Computing ML data\")\n",
    "        ds_ml_sampled = ds_ml_sampled.compute()\n",
    "        print(\"Computing NWP data\")\n",
    "        ds_nwp_sampled = ds_nwp_sampled.compute()\n",
    "        print(\"Computing GT data\")\n",
    "        ds_gt_sampled = ds_gt_sampled.compute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d31fbd",
   "metadata": {},
   "source": [
    "### 5. Various Verification Metrics\n",
    "The final chapter consolidates various statistical metrics to provide a broad\n",
    "evaluation of the ML model's performance. By considering multiple metrics, we\n",
    "gain a nuanced understanding of both the strengths and weaknesses of the model.\n",
    "\n",
    "**Metric Diversity:** Including MAE, RMSE, MSE, Pearson correlation, and the\n",
    "Fractions Skill Score (FSS) covers different aspects of model performance, from\n",
    "average errors to spatial pattern accuracy.\n",
    "\n",
    "**ME** (Mean Error): Indicates the average discrepancy between the model and ground truth values. A positive value indicates that the model tends to overestimate, while a negative value suggests underestimation. Also called Bias.\n",
    "\n",
    "**STDEV-ERR** (Standard Deviation of Errors): Shows the variability of errors, highlighting whether the model is consistent in its predictions.\n",
    "\n",
    "**MAE, MSE and RMSE:** Offer insights into the average magnitude of errors, with\n",
    "RMSE emphasizing larger discrepancies. The colors indicating high errors are\n",
    "only implemented for these three metrics with standardization.\n",
    "\n",
    "**Pearson Correlation:** Assesses the linear relationship, indicating whether\n",
    "the model captures variability even if biases exist.\n",
    "\n",
    "**FSS:** Evaluates spatial accuracy, which is particularly important for\n",
    "predicting localized weather events.\n",
    "\n",
    "**Wasserstein Distance:** Provides a holistic view of distributional similarity\n",
    "across variables. Same as chapter 3.\n",
    "\n",
    "**Holistic Assessment:** The combination of metrics provides a comprehensive\n",
    "performance profile, essential for model validation and comparison. More complex metrics are explained in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587f4294",
   "metadata": {},
   "source": [
    "#### Fractions Skill Score\n",
    "Range: 0 to 1, where:\n",
    "- 1 = perfect score\n",
    "- 0 = no skill compared to random chance\n",
    "\n",
    "**Key Properties:**\n",
    "- FSS measures the spatial agreement between two fields, accounting for the spatial scale of the features\n",
    "- It's particularly useful for assessing the spatial distribution of precipitation, cloud cover, or other fields with spatial structure\n",
    "- FSS is sensitive to the threshold used to define the presence of a feature, so it's important to choose an appropriate threshold\n",
    "- The FSS can be calculated for different spatial scales by defining the window size\n",
    "\n",
    "**Advantages:**\n",
    "- More meaningful than simple correlation for spatial fields\n",
    "- Accounts for the spatial scale of features\n",
    "- Provides a single value for the entire field comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2349084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These helper functions are only used to calculate the FSS threshold\n",
    "max_spatial_dim = np.maximum(ds_gt.x.size, ds_gt.y.size)\n",
    "window_size = (int(max_spatial_dim // 100),) * 2\n",
    "n_points = int(\n",
    "    np.minimum(\n",
    "        1e7,\n",
    "        ds_ml[list(VARIABLES_GROUND_TRUTH.values())[0]]\n",
    "        .isel(elapsed_forecast_duration=0)\n",
    "        .size,\n",
    "    )\n",
    ")\n",
    "print(f\"Using window size for FSS: {window_size}\")\n",
    "print(f\"Using n_points for FSS: {n_points}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffbfdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_by_efd(\n",
    "    ds_gt,\n",
    "    ds_ml,\n",
    "    ds_nwp=None,\n",
    "    metrics_to_compute=None,\n",
    "    window_size=3,\n",
    "    prefix=\"metrics\",\n",
    "):\n",
    "    \"\"\"Calculate metrics for each Elapsed Forecast Duration for gridded data.\"\"\"\n",
    "    if isinstance(window_size, (int, float)):\n",
    "        window_size = (int(window_size), int(window_size))\n",
    "\n",
    "    if metrics_to_compute is None:\n",
    "        metrics_to_compute = METRICS\n",
    "\n",
    "    variables = list(ds_gt.data_vars)\n",
    "    elapsed_forecast_durations = ds_ml.elapsed_forecast_duration\n",
    "    elapsed_forecast_durations_hours = elapsed_forecast_durations.values.astype(\n",
    "        \"timedelta64[s]\"\n",
    "    ) / np.timedelta64(1, \"h\")\n",
    "\n",
    "    metrics_by_efd = {}\n",
    "    combined_metrics = {}\n",
    "\n",
    "    # Added persistence forecast\n",
    "    per_fc = ds_gt.sel(time=ds_ml.start_time)\n",
    "\n",
    "    for efd, lt_hours in zip(\n",
    "        elapsed_forecast_durations, elapsed_forecast_durations_hours\n",
    "    ):\n",
    "        print(\n",
    "            f\"\\nCalculating metrics for elapsed forecast duration: {lt_hours.item():.1f}h\"\n",
    "        )\n",
    "\n",
    "        ds_ml_lead = ds_ml.sel(elapsed_forecast_duration=efd)\n",
    "        comp_for_nwp = (ds_nwp is not None) and (efd.values in ds_nwp.elapsed_forecast_duration)\n",
    "        if comp_for_nwp:\n",
    "            ds_nwp_lead = ds_nwp.sel(elapsed_forecast_duration=efd)\n",
    "\n",
    "        forecast_times = ds_ml_lead.forecast_time  # No .values\n",
    "        ds_gt_lead = ds_gt.sel(time=forecast_times)\n",
    "\n",
    "        metrics_dict = {}\n",
    "\n",
    "        #print(f\"ds_ml_lead: {ds_ml_lead}\")\n",
    "        #print(ds_ml_lead.start_time)\n",
    "        #print(f\"ds_nwp_lead: {ds_nwp_lead}\")\n",
    "        #print(ds_nwp_lead.start_time)\n",
    "        #print(f\"per_fc: {per_fc}\")\n",
    "\n",
    "        for var in variables:\n",
    "            print(f\"Processing {var}\")\n",
    "\n",
    "            # Get data as xarray DataArrays\n",
    "            y_true = ds_gt_lead[var]\n",
    "            y_pred_ml = ds_ml_lead[var]\n",
    "            y_pred_per = per_fc[var]\n",
    "\n",
    "            if comp_for_nwp and var in ds_nwp_lead:\n",
    "                y_pred_nwp = ds_nwp_lead[var]\n",
    "\n",
    "            # Not doing FSS for now, so don't need this\n",
    "            # quantile_90 = y_true.quantile(0.9).values\n",
    "            # print(\"90th quantile for FSS threshold:\", quantile_90)\n",
    "\n",
    "            metrics_dict[var] = {}\n",
    "\n",
    "            # Calculate ML metrics\n",
    "            if \"MAE\" in metrics_to_compute:\n",
    "                metrics_dict[var][\"MAE ML\"] = mae(y_pred_ml, y_true).values\n",
    "            if \"RMSE\" in metrics_to_compute:\n",
    "                metrics_dict[var][\"RMSE ML\"] = rmse(y_pred_ml, y_true).values\n",
    "            if \"MSE\" in metrics_to_compute:\n",
    "                metrics_dict[var][\"MSE ML\"] = mse(y_pred_ml, y_true).values\n",
    "            if \"ME\" in metrics_to_compute:\n",
    "                metrics_dict[var][\"ME ML\"] = mean_error(\n",
    "                    y_pred_ml, y_true\n",
    "                ).values\n",
    "            if \"STDEV_ERR\" in metrics_to_compute:\n",
    "                metrics_dict[var][\"STDEV_ERR ML\"] = (\n",
    "                    (y_pred_ml - y_true).std().values\n",
    "                )\n",
    "            if \"RelativeMAE\" in metrics_to_compute:\n",
    "                rel_mae = (\n",
    "                    abs(y_pred_ml - y_true) / (abs(y_true) + 1e-6)\n",
    "                ).mean()\n",
    "                metrics_dict[var][\"RelativeMAE ML\"] = rel_mae.values\n",
    "            if \"RelativeRMSE\" in metrics_to_compute:\n",
    "                rel_rmse = np.sqrt(\n",
    "                    ((y_pred_ml - y_true) ** 2 / (y_true**2 + 1e-6)).mean()\n",
    "                )\n",
    "                metrics_dict[var][\"RelativeRMSE ML\"] = rel_rmse.values\n",
    "            if \"PearsonR\" in metrics_to_compute:\n",
    "                metrics_dict[var][\"PearsonR ML\"] = pearsonr(\n",
    "                    y_pred_ml, y_true\n",
    "                ).values\n",
    "            if \"FSS\" in metrics_to_compute:\n",
    "                metrics_dict[var][\"FSS ML\"] = fss_2d(\n",
    "                    y_pred_ml.compute(),\n",
    "                    y_true.compute(),\n",
    "                    event_threshold=quantile_90,\n",
    "                    window_size=window_size,\n",
    "                    spatial_dims=[\"y\", \"x\"],\n",
    "                ).values\n",
    "            if \"Wasserstein\" in metrics_to_compute:\n",
    "                pred_vals = y_pred_ml.values\n",
    "                true_vals = y_true.values\n",
    "                metrics_dict[var][\"Wasserstein ML\"] = wasserstein_distance(\n",
    "                    pred_vals, true_vals\n",
    "                )\n",
    "\n",
    "            # Persistence\n",
    "            if \"RMSE\" in metrics_to_compute:\n",
    "                metrics_dict[var][\"RMSE Persistence\"] = rmse(y_pred_per, y_true).values\n",
    "\n",
    "            # Calculate NWP metrics if available\n",
    "            if comp_for_nwp and var in ds_nwp:\n",
    "                if \"MAE\" in metrics_to_compute:\n",
    "                    metrics_dict[var][\"MAE NWP\"] = mae(\n",
    "                        y_pred_nwp, y_true\n",
    "                    ).values\n",
    "                if \"RMSE\" in metrics_to_compute:\n",
    "                    metrics_dict[var][\"RMSE NWP\"] = rmse(\n",
    "                        y_pred_nwp, y_true\n",
    "                    ).values\n",
    "                if \"MSE\" in metrics_to_compute:\n",
    "                    metrics_dict[var][\"MSE NWP\"] = mse(\n",
    "                        y_pred_nwp, y_true\n",
    "                    ).values\n",
    "                if \"ME\" in metrics_to_compute:\n",
    "                    metrics_dict[var][\"ME NWP\"] = mean_error(\n",
    "                        y_pred_nwp, y_true\n",
    "                    ).values\n",
    "                if \"STDEV_ERR\" in metrics_to_compute:\n",
    "                    metrics_dict[var][\"STDEV_ERR NWP\"] = (\n",
    "                        (y_pred_nwp - y_true).std().values\n",
    "                    )\n",
    "                if \"RelativeMAE\" in metrics_to_compute:\n",
    "                    rel_mae = (\n",
    "                        abs(y_pred_nwp - y_true) / (abs(y_true) + 1e-6)\n",
    "                    ).mean()\n",
    "                    metrics_dict[var][\"RelativeMAE NWP\"] = rel_mae.values\n",
    "                if \"RelativeRMSE\" in metrics_to_compute:\n",
    "                    rel_rmse = np.sqrt(\n",
    "                        ((y_pred_nwp - y_true) ** 2 / (y_true**2 + 1e-6)).mean()\n",
    "                    )\n",
    "                    metrics_dict[var][\"RelativeRMSE NWP\"] = rel_rmse.values\n",
    "                if \"PearsonR\" in metrics_to_compute:\n",
    "                    metrics_dict[var][\"PearsonR NWP\"] = pearsonr(\n",
    "                        y_pred_nwp, y_true\n",
    "                    ).values\n",
    "                if \"FSS\" in metrics_to_compute:\n",
    "                    metrics_dict[var][\"FSS NWP\"] = fss_2d(\n",
    "                        y_pred_nwp.compute(),\n",
    "                        y_true.compute(),\n",
    "                        event_threshold=quantile_90,\n",
    "                        window_size=window_size,\n",
    "                        spatial_dims=[\"y\", \"x\"],\n",
    "                    ).values\n",
    "                if \"Wasserstein\" in metrics_to_compute:\n",
    "                    pred_vals = y_pred_nwp.values\n",
    "                    true_vals = y_true.values\n",
    "                    metrics_dict[var][\"Wasserstein NWP\"] = wasserstein_distance(\n",
    "                        pred_vals, true_vals\n",
    "                    )\n",
    "\n",
    "            # Store combined metrics\n",
    "            for metric_name, value in metrics_dict[var].items():\n",
    "                key = f\"{var}_{metric_name}\"\n",
    "                if key not in combined_metrics:\n",
    "                    combined_metrics[key] = []\n",
    "                combined_metrics[key].append(value)\n",
    "\n",
    "        metrics_by_efd[lt_hours.item()] = pd.DataFrame.from_dict(\n",
    "            metrics_dict, orient=\"index\"\n",
    "        )\n",
    "\n",
    "    # Create combined metrics DataFrame\n",
    "    #elapsed_forecast_durations_hours_float = [\n",
    "    #    x.item() for x in elapsed_forecast_durations_hours\n",
    "    #]\n",
    "    #combined_df = pd.DataFrame(\n",
    "    #    combined_metrics, index=elapsed_forecast_durations_hours_float\n",
    "    #)\n",
    "    #combined_df.index.name = \"Forecast Hours\"\n",
    "    #export_table(combined_df, f\"{prefix}\", \"Combined metrics\")\n",
    "\n",
    "    return metrics_by_efd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e996dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with (\n",
    "#     LocalCluster(\n",
    "#         n_workers=1,\n",
    "#         threads_per_worker=32,\n",
    "#         memory_limit=\"48GB\",\n",
    "#         local_directory=\"/iopsstor/scratch/cscs/sadamov\",  # Use fast local storage for spilling\n",
    "#         dashboard_address=None,\n",
    "#     ) as cluster\n",
    "# ):\n",
    "#     with Client(cluster) as client:\n",
    "metrics_by_efd = calculate_metrics_by_efd(\n",
    "    ds_gt=ds_gt,\n",
    "    ds_ml=ds_ml_sampled,\n",
    "    ds_nwp=ds_nwp_sampled,\n",
    "    prefix=\"combined_metrics\",\n",
    ")\n",
    "metrics_by_efd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5335508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot evolution of a specific metric over elapsed forecast duration\n",
    "elapsed_forecast_durations = list(metrics_by_efd.keys())\n",
    "for i, variable in enumerate(VARIABLES_GROUND_TRUTH.values()):\n",
    "    for metric in METRICS:\n",
    "        try:\n",
    "            # Skip if any scores are missing\n",
    "            ml_scores = [\n",
    "                df.loc[variable, f\"{metric} ML\"]\n",
    "                for df in metrics_by_efd.values()\n",
    "            ]\n",
    "\n",
    "            # Convert elapsed forecast durations from hours to timedelta\n",
    "            hours = [\n",
    "                x / np.timedelta64(1, \"h\")\n",
    "                for x in ds_ml.elapsed_forecast_duration.values\n",
    "            ]\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(10, 6), dpi=DPI)\n",
    "\n",
    "            # Plot ML scores\n",
    "            ax.plot(\n",
    "                hours,\n",
    "                ml_scores,\n",
    "                label=\"ML\" if i == 0 else \"\",\n",
    "                color=COLORS[\"ml\"],\n",
    "                linestyle=LINE_STYLES[\"ml\"][0],\n",
    "                marker=LINE_STYLES[\"ml\"][1],\n",
    "            )\n",
    "\n",
    "            nwp_metric_name = f\"{metric} NWP\"\n",
    "            nwp_scores = [\n",
    "                df.loc[variable, nwp_metric_name]\n",
    "                for df in metrics_by_efd.values() if nwp_metric_name in df\n",
    "            ]\n",
    "\n",
    "            # Plot NWP scores if they exist and are not all NaN\n",
    "            if nwp_scores and not all(pd.isna(nwp_scores)):\n",
    "                hours_nwp = [\n",
    "                    x / np.timedelta64(1, \"h\")\n",
    "                    for x in ds_nwp.elapsed_forecast_duration.values\n",
    "                ]\n",
    "\n",
    "                ax.plot(\n",
    "                    hours_nwp,\n",
    "                    nwp_scores,\n",
    "                    label=\"NWP\" if i == 0 else \"\",\n",
    "                    color=COLORS[\"nwp\"],\n",
    "                    linestyle=LINE_STYLES[\"nwp\"][0],\n",
    "                    marker=LINE_STYLES[\"nwp\"][1],\n",
    "                )\n",
    "\n",
    "            # Persistence\n",
    "            per_metric_name = f\"{metric} Persistence\"\n",
    "            per_scores = [\n",
    "                df.loc[variable, per_metric_name]\n",
    "                for df in metrics_by_efd.values() if per_metric_name in df\n",
    "            ]\n",
    "\n",
    "            # Plot NWP scores if they exist and are not all NaN\n",
    "            if per_scores and not all(pd.isna(per_scores)):\n",
    "                hours_per = [\n",
    "                    x / np.timedelta64(1, \"h\")\n",
    "                    for x in ds_ml.elapsed_forecast_duration.values # From ml data\n",
    "                ]\n",
    "\n",
    "                ax.plot(\n",
    "                    hours_per,\n",
    "                    per_scores,\n",
    "                    label=\"Persistence\" if i == 0 else \"\",\n",
    "                    color=COLORS[\"per\"],\n",
    "                    linestyle=LINE_STYLES[\"per\"][0],\n",
    "                    marker=LINE_STYLES[\"per\"][1],\n",
    "                )\n",
    "\n",
    "            ax.set_xlabel(\"Elapsed Forecast Duration (h)\")\n",
    "            ax.set_ylabel(f\"{metric} ({VARIABLE_UNITS[variable]})\")\n",
    "            ax.set_title(f\"{metric} Evolution for {variable}\")\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "            # Only show legend for first variable\n",
    "            if i == 0:\n",
    "                ax.legend()\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            save_plot(fig, f\"{metric}_{variable}_evolution\")\n",
    "            plt.close()\n",
    "\n",
    "        except (KeyError, ValueError) as e:\n",
    "            print(f\"Skipping {metric} for {variable}: {str(e)}\")\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98bd034",
   "metadata": {},
   "source": [
    "#### Equitable Threat Score (Traditional Version)\n",
    "Range: [-1/3, 1], where:\n",
    "- 1 = perfect score\n",
    "- 0 = no skill compared to random chance\n",
    "- -1/3 = worst possible performance\n",
    "\n",
    "**Key Properties:**\n",
    "- Measures how well predicted events correspond to observed events, accounting for hits due to random chance\n",
    "- Particularly useful for rare events (like precipitation above a high threshold)\n",
    "- More equitable than simple Threat Score by accounting for hits due to random chance\n",
    "\n",
    "**Advantages:**\n",
    "- Well-established metric in meteorological verification\n",
    "- Reference point at 0 makes interpretation clear\n",
    "- Penalizes both misses and false alarms\n",
    "- Accounts for random chance, making it more robust than basic threat scores\n",
    "\n",
    "#### Frequency Bias Index\n",
    "Range: 0 to infinity, where:\n",
    "- 1 = no bias\n",
    "- < 1 = underforecasting\n",
    "- > 1 = overforecasting\n",
    "\n",
    "**Key Properties:**\n",
    "- FBI measures the ratio of observed to forecasted events, indicating whether the model tends to over- or underforecast\n",
    "- It's particularly useful for understanding systematic biases in event frequency\n",
    "\n",
    "**Advantages:**\n",
    "- Provides a clear indication of over- or underforecasting\n",
    "- Easy to interpret: 1 indicates no bias, while values above or below 1 show the direction and magnitude of the bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6257057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options for all float values\n",
    "pd.set_option(\"display.float_format\", lambda x: \"{:.4f}\".format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cafe5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_meteoswiss_metrics(ds_gt, ds_ml, ds_nwp):\n",
    "    \"\"\"Calculate MeteoSwiss verification metrics\"\"\"\n",
    "    metrics_by_var = {}\n",
    "\n",
    "    # Get available variables in each dataset\n",
    "    gt_ml_vars = set(ds_gt.variables) & set(ds_ml.variables)\n",
    "    nwp_vars = set(ds_nwp.variables) if ds_nwp is not None else set()\n",
    "\n",
    "    all_variables = {\n",
    "        \"precipitation\": {\n",
    "            \"thresholds\": THRESHOLDS_PRECIPITATION,\n",
    "            \"unit\": \"mm/h\",\n",
    "        },\n",
    "        \"wind_u_10m\": {\"thresholds\": THRESHOLDS_WIND, \"unit\": \"m/s\"},\n",
    "        \"wind_v_10m\": {\"thresholds\": THRESHOLDS_WIND, \"unit\": \"m/s\"},\n",
    "    }\n",
    "\n",
    "    # Filter variables that exist in gt and ml\n",
    "    all_variables = {k: v for k, v in all_variables.items() if k in gt_ml_vars}\n",
    "\n",
    "    # Initialize metrics structure\n",
    "    for var_name in all_variables:\n",
    "        metrics_by_var[var_name] = {}\n",
    "        for thr in all_variables[var_name][\"thresholds\"]:\n",
    "            metric_key = f\"{thr}{all_variables[var_name]['unit']}\"\n",
    "            metrics_by_var[var_name][metric_key] = {\n",
    "                \"FBI_ML\": [],\n",
    "                \"ETS_ML\": [],\n",
    "                \"FBI_NWP\": [] if ds_nwp is not None else None,\n",
    "                \"ETS_NWP\": [] if ds_nwp is not None else None,\n",
    "            }\n",
    "\n",
    "    for efd in ds_ml.elapsed_forecast_duration.values:\n",
    "        try:\n",
    "            print(\n",
    "                f\"\\nCalculating metrics for elapsed forecast duration: {efd / np.timedelta64(1, 'h'):.1f}h\"\n",
    "            )\n",
    "\n",
    "            ds_ml_lead = ds_ml.sel(elapsed_forecast_duration=efd)\n",
    "            ds_nwp_lead = (\n",
    "                ds_nwp.sel(elapsed_forecast_duration=efd)\n",
    "                if ds_nwp is not None\n",
    "                else None\n",
    "            )\n",
    "            forecast_times = ds_ml_lead.forecast_time # No .values\n",
    "            ds_gt_lead = ds_gt.sel(time=forecast_times)\n",
    "\n",
    "            for var_name, var_config in all_variables.items():\n",
    "                print(f\"Processing {var_name}\")\n",
    "                try:\n",
    "                    # Get data\n",
    "                    y_true = ds_gt_lead[var_name]\n",
    "                    y_ml = ds_ml_lead[var_name]\n",
    "                    y_nwp = (\n",
    "                        ds_nwp_lead[var_name]\n",
    "                        if ds_nwp_lead is not None and var_name in nwp_vars\n",
    "                        else None\n",
    "                    )\n",
    "\n",
    "                    for thr in var_config[\"thresholds\"]:\n",
    "                        metric_key = f\"{thr}{var_config['unit']}\"\n",
    "\n",
    "                        # Calculate ML metrics using TEO\n",
    "                        event_operator = TEO(default_event_threshold=thr)\n",
    "                        ml_contingency = (\n",
    "                            event_operator.make_contingency_manager(\n",
    "                                y_ml, y_true\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "                        fbi_ml = ml_contingency.frequency_bias().values\n",
    "                        ets_ml = ml_contingency.equitable_threat_score().values\n",
    "\n",
    "                        metrics_by_var[var_name][metric_key][\"FBI_ML\"].append(\n",
    "                            fbi_ml\n",
    "                        )\n",
    "                        metrics_by_var[var_name][metric_key][\"ETS_ML\"].append(\n",
    "                            ets_ml\n",
    "                        )\n",
    "\n",
    "                        # Calculate NWP metrics if available\n",
    "                        if y_nwp is not None:\n",
    "                            nwp_contingency = (\n",
    "                                event_operator.make_contingency_manager(\n",
    "                                    y_nwp, y_true\n",
    "                                )\n",
    "                            )\n",
    "                            fbi_nwp = nwp_contingency.frequency_bias().values\n",
    "                            ets_nwp = (\n",
    "                                nwp_contingency.equitable_threat_score().values\n",
    "                            )\n",
    "\n",
    "                            metrics_by_var[var_name][metric_key][\n",
    "                                \"FBI_NWP\"\n",
    "                            ].append(fbi_nwp)\n",
    "                            metrics_by_var[var_name][metric_key][\n",
    "                                \"ETS_NWP\"\n",
    "                            ].append(ets_nwp)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {var_name}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing elapsed forecast duration {efd}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    return metrics_by_var\n",
    "\n",
    "def plot_metrics_evolution(\n",
    "    metrics_by_var,\n",
    "    elapsed_forecast_durations,\n",
    "    var_name,\n",
    "    metric_name,\n",
    "    var_index=0,\n",
    "):\n",
    "    \"\"\"Plot evolution of FBI/ETS metrics over elapsed forecast durations for gridded data.\"\"\"\n",
    "    try:\n",
    "        if not metrics_by_var or var_name not in metrics_by_var:\n",
    "            print(f\"No metrics data available for {var_name}\")\n",
    "            return\n",
    "\n",
    "        # Convert timedelta to hours for x-axis\n",
    "        forecast_hours = [\n",
    "            efd / np.timedelta64(1, \"h\") for efd in elapsed_forecast_durations\n",
    "        ]\n",
    "\n",
    "        # Get three fixed colors from viridis\n",
    "        colors = [plt.cm.viridis(x) for x in [0, 0.5, 0.99]]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 6), dpi=DPI)\n",
    "\n",
    "        # Plot for each threshold\n",
    "        for i, (threshold, metrics) in enumerate(\n",
    "            metrics_by_var[var_name].items()\n",
    "        ):\n",
    "            # Plot ML metrics\n",
    "            if metrics[\"FBI_ML\"]:  # Check if we have ML metrics\n",
    "                ax.plot(\n",
    "                    forecast_hours,\n",
    "                    metrics[f\"{metric_name}_ML\"],\n",
    "                    linestyle=LINE_STYLES[\"ml\"][0],\n",
    "                    marker=LINE_STYLES[\"ml\"][1],\n",
    "                    color=colors[i],\n",
    "                    label=f\"ML {threshold}\" if var_index == 0 else \"\",\n",
    "                )\n",
    "\n",
    "            # Plot NWP metrics if available\n",
    "            if metrics[f\"{metric_name}_NWP\"]:  # Check if we have NWP metrics\n",
    "                ax.plot(\n",
    "                    forecast_hours,\n",
    "                    metrics[f\"{metric_name}_NWP\"],\n",
    "                    linestyle=LINE_STYLES[\"nwp\"][0],\n",
    "                    marker=LINE_STYLES[\"nwp\"][1],\n",
    "                    color=colors[i],\n",
    "                    label=f\"NWP {threshold}\" if var_index == 0 else \"\",\n",
    "                )\n",
    "\n",
    "        ax.set_xlabel(\"Elapsed Forecast Duration (h)\")\n",
    "        ax.set_ylabel(metric_name)\n",
    "        ax.set_title(f\"{metric_name} Evolution for {var_name}\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # Only show legend for first variable\n",
    "        if var_index == 0:\n",
    "            ax.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        save_plot(fig, f\"{metric_name.lower()}_{var_name}_evolution\")\n",
    "        plt.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting {var_name} - {metric_name}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af80d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_metrics_by_var(metrics_by_var, elapsed_forecast_durations):\n",
    "    \"\"\"Reshape the metrics dictionary into a DataFrame with thresholds as columns\"\"\"\n",
    "    # Convert forecast durations to hours for index\n",
    "    forecast_hours = [\n",
    "        efd / np.timedelta64(1, \"h\") for efd in elapsed_forecast_durations\n",
    "    ]\n",
    "\n",
    "    # Create a list to store all data\n",
    "    data = []\n",
    "\n",
    "    # Iterate through each forecast hour\n",
    "    for idx, hour in enumerate(forecast_hours):\n",
    "        row_data = {\"forecast_hour\": hour}\n",
    "\n",
    "        # Iterate through each variable and its thresholds\n",
    "        for var_name, thresholds in metrics_by_var.items():\n",
    "            for threshold, metrics in thresholds.items():\n",
    "                # Add ML metrics if they exist and have values\n",
    "                if metrics[\"FBI_ML\"] is not None:\n",
    "                    row_data[f\"{var_name}_{threshold}_FBI_ML\"] = metrics[\n",
    "                        \"FBI_ML\"\n",
    "                    ][idx]\n",
    "                    row_data[f\"{var_name}_{threshold}_ETS_ML\"] = metrics[\n",
    "                        \"ETS_ML\"\n",
    "                    ][idx]\n",
    "\n",
    "                # Add NWP metrics if they exist and have values\n",
    "                if metrics[\"FBI_NWP\"] is not None:\n",
    "                    row_data[f\"{var_name}_{threshold}_FBI_NWP\"] = metrics[\n",
    "                        \"FBI_NWP\"\n",
    "                    ][idx]\n",
    "                    row_data[f\"{var_name}_{threshold}_ETS_NWP\"] = metrics[\n",
    "                        \"ETS_NWP\"\n",
    "                    ][idx]\n",
    "\n",
    "        data.append(row_data)\n",
    "\n",
    "    # Create DataFrame from collected data\n",
    "    df = pd.DataFrame(data)\n",
    "    df.set_index(\"forecast_hour\", inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Modify the main execution block:\n",
    "try:\n",
    "    print(\"Calculating MeteoSwiss metrics...\")\n",
    "    metrics_by_var = calculate_meteoswiss_metrics(\n",
    "        ds_gt,\n",
    "        ds_ml_sampled.isel(elapsed_forecast_duration=ELAPSED_FORECAST_DURATION_SHORT),\n",
    "        ds_nwp_sampled.isel(elapsed_forecast_duration=ELAPSED_FORECAST_DURATION_SHORT)\n",
    "    )\n",
    "\n",
    "    # Reshape and export metrics to table\n",
    "    elapsed_forecast_durations = ds_ml.isel(elapsed_forecast_duration=ELAPSED_FORECAST_DURATION_SHORT).elapsed_forecast_duration.values\n",
    "    metrics_df = reshape_metrics_by_var(\n",
    "        metrics_by_var, elapsed_forecast_durations\n",
    "    )\n",
    "\n",
    "    export_table(\n",
    "        metrics_df,\n",
    "        \"meteoswiss_metrics\",\n",
    "        \"MeteoSwiss verification metrics (FBI and ETS)\",\n",
    "    )\n",
    "\n",
    "    # Plot metrics for each variable\n",
    "    for i, var_name in enumerate(metrics_by_var):\n",
    "        for metric_name in [\"FBI\", \"ETS\"]:\n",
    "            plot_metrics_evolution(\n",
    "                metrics_by_var,\n",
    "                elapsed_forecast_durations,\n",
    "                var_name,\n",
    "                metric_name,\n",
    "                var_index=i\n",
    "            )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in main execution: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9e104e",
   "metadata": {},
   "source": [
    "The wind vector RMSE takes into account the magnitude and direction of the wind, providing a more comprehensive measure of error than scalar metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3847e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wind_vector_rmse(u_pred, v_pred, u_true, v_true):\n",
    "    \"\"\"Calculate RMSE based on wind vector differences.\"\"\"\n",
    "    rmse_u = rmse(u_true, u_pred)\n",
    "    rmse_v = rmse(v_true, v_pred)\n",
    "    rmse_wind = np.sqrt(rmse_u**2 + rmse_v**2)\n",
    "    return float(rmse_wind)\n",
    "\n",
    "\n",
    "# Initialize results dictionary\n",
    "results_wind = {\"vector_metrics\": {}}\n",
    "elapsed_forecast_durations = ds_ml_sampled.elapsed_forecast_duration.values\n",
    "\n",
    "# Lists to store RMSE values over time\n",
    "ml_rmse_over_time = []\n",
    "per_rmse_over_time = []\n",
    "nwp_rmse_over_time = []\n",
    "forecast_hours = [\n",
    "    efd / np.timedelta64(1, \"h\") for efd in elapsed_forecast_durations\n",
    "]\n",
    "\n",
    "if \"wind_u_10m\" in ds_gt and \"wind_v_10m\" in ds_gt:\n",
    "    \n",
    "    # Persistence\n",
    "    u_per = ds_gt[\"wind_u_10m\"].sel(time=ds_ml_sampled.start_time)\n",
    "    v_per = ds_gt[\"wind_v_10m\"].sel(time=ds_ml_sampled.start_time)\n",
    "    \n",
    "    for efd in elapsed_forecast_durations:\n",
    "        print(f\"Calculating wind vector RMSE for EFD: {efd}\")\n",
    "        # Get corresponding forecast times\n",
    "        forecast_times = ds_ml_sampled.sel(\n",
    "            elapsed_forecast_duration=efd\n",
    "        ).forecast_time # No .values\n",
    "\n",
    "        # Get wind components for specific forecast time\n",
    "        u_true = ds_gt[\"wind_u_10m\"].sel(time=forecast_times)\n",
    "        v_true = ds_gt[\"wind_v_10m\"].sel(time=forecast_times)\n",
    "        u_ml = ds_ml_sampled[\"wind_u_10m\"].sel(elapsed_forecast_duration=efd)\n",
    "        v_ml = ds_ml_sampled[\"wind_v_10m\"].sel(elapsed_forecast_duration=efd)\n",
    "\n",
    "        # Calculate ML RMSE\n",
    "        wind_rmse_ml = wind_vector_rmse(u_ml, v_ml, u_true, v_true)\n",
    "        ml_rmse_over_time.append(wind_rmse_ml)\n",
    "\n",
    "        # Calculate Per RMSE\n",
    "        wind_rmse_per = wind_vector_rmse(u_per, v_per, u_true, v_true)\n",
    "        per_rmse_over_time.append(wind_rmse_per)\n",
    "\n",
    "        # Calculate NWP RMSE if available\n",
    "        if (\"wind_u_10m\" in ds_nwp \n",
    "            and \"wind_v_10m\" in ds_nwp\n",
    "            and efd in ds_nwp_sampled.elapsed_forecast_duration\n",
    "        ):\n",
    "            u_nwp = ds_nwp_sampled[\"wind_u_10m\"].sel(elapsed_forecast_duration=efd)\n",
    "            v_nwp = ds_nwp_sampled[\"wind_v_10m\"].sel(elapsed_forecast_duration=efd)\n",
    "            wind_rmse_nwp = wind_vector_rmse(u_nwp, v_nwp, u_true, v_true)\n",
    "            nwp_rmse_over_time.append(wind_rmse_nwp)\n",
    "        else:\n",
    "            nwp_rmse_over_time.append(np.nan)\n",
    "\n",
    "    # Create time series DataFrame\n",
    "    time_series_df = pd.DataFrame({\n",
    "        \"Elapsed Forecast Duration\": forecast_hours,\n",
    "        \"ML RMSE\": ml_rmse_over_time,\n",
    "        \"Per RMSE\": per_rmse_over_time,\n",
    "        \"NWP RMSE\": nwp_rmse_over_time,\n",
    "    })\n",
    "\n",
    "    # Plot RMSE over time\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot ML model\n",
    "    ax.plot(\n",
    "        forecast_hours,\n",
    "        ml_rmse_over_time,\n",
    "        linestyle=LINE_STYLES[\"ml\"][0],\n",
    "        marker=LINE_STYLES[\"ml\"][1],\n",
    "        label=\"ML\",\n",
    "        color=COLORS[\"ml\"],\n",
    "    )\n",
    "\n",
    "    # Plot Per model\n",
    "    ax.plot(\n",
    "        forecast_hours,\n",
    "        per_rmse_over_time,\n",
    "        linestyle=LINE_STYLES[\"per\"][0],\n",
    "        marker=LINE_STYLES[\"per\"][1],\n",
    "        label=\"Persistence\",\n",
    "        color=COLORS[\"per\"],\n",
    "    )\n",
    "\n",
    "    # Plot NWP model if available\n",
    "    if not all(np.isnan(nwp_rmse_over_time)):\n",
    "        ax.plot(\n",
    "            forecast_hours,\n",
    "            nwp_rmse_over_time,\n",
    "            linestyle=LINE_STYLES[\"nwp\"][0],\n",
    "            marker=LINE_STYLES[\"nwp\"][1],\n",
    "            label=\"NWP\",\n",
    "            color=COLORS[\"nwp\"],\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"Elapsed Forecast Duration (h)\")\n",
    "    ax.set_ylabel(\"Wind Vector RMSE (m/s)\")\n",
    "    ax.set_title(\"Wind Vector RMSE Evolution\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    save_plot(fig, \"wind_vector_rmse_evolution\")\n",
    "\n",
    "    export_table(\n",
    "        time_series_df,\n",
    "        \"wind_vector_metrics_timeseries\",\n",
    "        caption=\"Wind vector RMSE over forecast duration\",\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
