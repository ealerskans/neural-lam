{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de5d8017",
   "metadata": {},
   "source": [
    "##  Gridded Model Verification\n",
    "\n",
    "This script verifies output from a ML-based foundation model versus a\n",
    "traditional NWP system for the atmospheric system. The defaults set at the top of\n",
    "this script are tailored to the Alps-Clariden HPC system at CSCS.\n",
    "- The NWP-model is called DANRA-forecasts and is initialised with the analysis. Only surface level data is available, and up to 18 h lead time.\n",
    "- The ML-model is called Neural-LAM and is initialised from the DANRA reanalysis.\n",
    "- The Ground Truth is the same deterministic DANRA reanalysis as was used to train the ML-model.\n",
    "- The boundary data for both models is IFS HRES from ECMWF, where the NWP-model got 6 hourly boundary updates (?) and the ML model 12 hourly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0311b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import dask\n",
    "import matplotlib.pyplot as plt\n",
    "from dask.distributed import LocalCluster, Client\n",
    "import numpy as np\n",
    "from dask.diagnostics import ProgressBar\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from pysteps.verification.salscores import sal  # requires scikit-image\n",
    "from scipy.stats import kurtosis, skew, wasserstein_distance\n",
    "from scores.categorical import ThresholdEventOperator as TEO\n",
    "from scores.continuous import (\n",
    "    mae,\n",
    "    mean_error,\n",
    "    mse,\n",
    "    rmse,\n",
    ")\n",
    "from scores.continuous.correlation import pearsonr\n",
    "from scores.spatial import fss_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a806b47",
   "metadata": {},
   "source": [
    "**--------> Enter all your user settings in the cell below. <--------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf621a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFAULTS ###\n",
    "# This config will be applied to the data before any plotting. The data will be\n",
    "# sliced and indexed according to the values in this config.The whole analysis and\n",
    "# plotting will be done on the reduced data.\n",
    "\n",
    "# IF YOUR DATA HAS DIFFERENT DIMENSIONS OR NAMES, PLEASE ADJUST THE CELLS BELOW\n",
    "# MAKE SURE THE XARRAY DATASETS LOOK OKAY BEFORE RUNNING CHAPTER 1-4\n",
    "\n",
    "# This path should point to the data that was used to train the model (default is mdp-datastore)\n",
    "PATH_GROUND_TRUTH = \"danra_test_gt.zarr\"\n",
    "# This path should point to the NWP forecast data in zarr format\n",
    "PATH_NWP = \"danra_test_nwp_forecasts.zarr\"\n",
    "# This path should point to the ML forecast data in zarr format (e.g. produced by neural-lam in `eval` mode)\n",
    "PATH_ML = \"48h_eval_test_7deg_rect_hi4_2867.zarr\"\n",
    "# This path should point to the boundary data in zarr format (default is MDP-datastore)\n",
    "PATH_BOUNDARY = \"ifs_test_boundary.zarr\"\n",
    "\n",
    "# elapsed forecast duration in steps for the forecast - [0] refers to the first forecast step at t+1\n",
    "# this should be a list of integers\n",
    "ELAPSED_FORECAST_DURATION = list(range(16))\n",
    "ELAPSED_FORECAST_DURATION_SHORT = list(range(6)) # 18 h, matching NWP forecasts\n",
    "ELAPSED_FORECAST_DURATION_PLOT = [1,3,5] # ELS to plot\n",
    "ELAPSED_FORECAST_DURATION_VERTICAL = [0, 3, 7, 11, 15] # For vertical profiles\n",
    "\n",
    "# Select specific start_times for the forecast. This is the start and end of\n",
    "# a slice in xarray. The start_time is included, the end_time is excluded.\n",
    "# This should be a list of two strings in the format \"YYYY-MM-DDTHH:MM:SS\"\n",
    "# Should be handy to evaluate certain dates, e.g. for a case study of a storm\n",
    "#START_TIMES = [\"2020-02-07T00:00:00\", \"2020-02-10T00:00:00\"] # 7 init times, ~1% of full year\n",
    "START_TIMES = [\"2019-10-30T00:00\", \"2020-10-23T12:00\"] # Full year, 720 init times\n",
    "\n",
    "# Select specific plot times for the forecast (will be used to create maps for all variables)\n",
    "# This only affect chapter one with the plotting of the maps\n",
    "# Map creation takes a lot of time so this is limited to a single time step\n",
    "# Simply rerun these cells and chapter one for more time steps\n",
    "PLOT_TIME = \"2020-02-09T12:00:00\"\n",
    "\n",
    "# Selection spatial grid in projection\n",
    "# This is used to slice the data to a specific region\n",
    "# This is in projection of the ground truth data\n",
    "# The default is the whole domain [None, None]\n",
    "X = [None, None]\n",
    "Y = [None, None]\n",
    "\n",
    "# Map projection settings for plotting\n",
    "# This is the projection of the ground truth data\n",
    "PROJECTION = ccrs.LambertConformal(\n",
    "    central_longitude=25.0,\n",
    "    central_latitude=56.7,\n",
    "    standard_parallels=[56.7, 56.7],\n",
    "    globe=ccrs.Globe(\n",
    "        semimajor_axis=6367470.0,\n",
    "        semiminor_axis=6367470.0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Define how variables map between different data sources\n",
    "\n",
    "# Define here which of the variables are available in the ground truth data\n",
    "# The keys are the names of the variables in the ground truth data\n",
    "# The values are the conventional names, used in this notebook\n",
    "VARIABLES_GROUND_TRUTH = {\n",
    "    # Surface and near-surface variables\n",
    "    \"t2m\": \"temperature_2m\",\n",
    "    \"u10m\": \"wind_u_10m\",\n",
    "    \"v10m\": \"wind_v_10m\",\n",
    "    \"pres_seasurface\": \"pressure_sea_level\",\n",
    "    \"pres0m\": \"surface_pressure\",\n",
    "    \"swavr0m\": \"surface_net_shortwave_radiation\",\n",
    "    \"lwavr0m\": \"surface_net_longwave_radiation\",\n",
    "    # Upper air variables - U component\n",
    "    # \"u100\": \"wind_u_100hPa\",\n",
    "    \"u200\": \"wind_u_200hPa\",\n",
    "    # \"u400\": \"wind_u_400hPa\",\n",
    "    # \"u600\": \"wind_u_600hPa\",\n",
    "    \"u700\": \"wind_u_700hPa\",\n",
    "    # \"u850\": \"wind_u_850hPa\",\n",
    "    # \"u925\": \"wind_u_925hPa\",\n",
    "    # \"u1000\": \"wind_u_1000hPa\",\n",
    "    # Upper air variables - V component\n",
    "    # \"v100\": \"wind_v_100hPa\",\n",
    "    \"v200\": \"wind_v_200hPa\",\n",
    "    # \"v400\": \"wind_v_400hPa\",\n",
    "    # \"v600\": \"wind_v_600hPa\",\n",
    "    \"v700\": \"wind_v_700hPa\",\n",
    "    # \"v850\": \"wind_v_850hPa\",\n",
    "    # \"v925\": \"wind_v_925hPa\",\n",
    "    # \"v1000\": \"wind_v_1000hPa\",\n",
    "    # Upper air variables - Pressure\n",
    "    # \"z100\": \"geopotential_100hPa\",\n",
    "    # \"z200\": \"geopotential_200hPa\",\n",
    "    # \"z400\": \"geopotential_400hPa\",\n",
    "    # \"z600\": \"geopotential_600hPa\",\n",
    "    \"z700\": \"geopotential_700hPa\",\n",
    "    # \"z850\": \"geopotential_850hPa\",\n",
    "    # \"z925\": \"geopotential_925hPa\",\n",
    "    # \"z1000\": \"geopotential_1000hPa\",\n",
    "    # Upper air variables - Temperature\n",
    "    # \"t100\": \"temperature_100hPa\",\n",
    "    # \"t200\": \"temperature_200hPa\",\n",
    "    # \"t400\": \"temperature_400hPa\",\n",
    "    # \"t600\": \"temperature_600hPa\",\n",
    "    \"t700\": \"temperature_700hPa\",\n",
    "    # \"t850\": \"temperature_850hPa\",\n",
    "    # \"t925\": \"temperature_925hPa\",\n",
    "    # \"t1000\": \"temperature_1000hPa\",\n",
    "    # Upper air variables - Relative Humidity\n",
    "    # \"r100\": \"relative_humidity_100hPa\",\n",
    "    \"r200\": \"relative_humidity_200hPa\",\n",
    "    # \"r400\": \"relative_humidity_400hPa\",\n",
    "    # \"r600\": \"relative_humidity_600hPa\",\n",
    "    \"r700\": \"relative_humidity_700hPa\",\n",
    "    # \"r850\": \"relative_humidity_850hPa\",\n",
    "    # \"r925\": \"relative_humidity_925hPa\",\n",
    "    # \"r1000\": \"relative_humidity_1000hPa\",\n",
    "    # Upper air variables - Vertical velocity\n",
    "    # \"tw100\": \"vertical_velocity_100hPa\",\n",
    "    \"tw200\": \"vertical_velocity_200hPa\",\n",
    "    # \"tw400\": \"vertical_velocity_400hPa\",\n",
    "    # \"tw600\": \"vertical_velocity_600hPa\",\n",
    "    \"tw700\": \"vertical_velocity_700hPa\",\n",
    "    # \"tw850\": \"vertical_velocity_850hPa\",\n",
    "    # \"tw925\": \"vertical_velocity_925hPa\",\n",
    "    # \"tw1000\": \"vertical_velocity_1000hPa\",\n",
    "}\n",
    "\n",
    "REQUIRED_LEVELS = [\n",
    "    100,\n",
    "    200,\n",
    "    400,\n",
    "    600,\n",
    "    700,\n",
    "    850,\n",
    "    925,\n",
    "    1000,\n",
    "]\n",
    "\n",
    "# Since the default ground_truth is the datastore that was used for model training\n",
    "# the variables are identical to the VARIABLES_GROUND_TRUTH\n",
    "VARIABLES_ML = VARIABLES_GROUND_TRUTH\n",
    "\n",
    "# For the NWP-Forecast only a limited set of variables is available\n",
    "# These variables are mapped to the same conventional names\n",
    "# The script is flexible and will only calculate the NWP-metrics for the variables that are available\n",
    "# The script will not break if some of the variables are not available\n",
    "VARIABLES_NWP = {\n",
    "    \"t2m\": \"temperature_2m\",\n",
    "    \"u10m\": \"wind_u_10m\",\n",
    "    \"v10m\": \"wind_v_10m\",\n",
    "    \"pres_seasurface\": \"seasurface_pressure\",\n",
    "}\n",
    "\n",
    "# These variables are only used for chapter 1, the mapplots.\n",
    "# They will be plotted for the ground truth, NWP and ML\n",
    "VARIABLES_BOUNDARY = {\n",
    "    # Surface and near-surface variables\n",
    "    \"mean_sea_level_pressure\": \"pressure_sea_level\",\n",
    "    \"2m_temperature\": \"temperature_2m\",\n",
    "    \"10m_u_component_of_wind\": \"wind_u_10m\",\n",
    "    \"10m_v_component_of_wind\": \"wind_v_10m\",\n",
    "    \"surface_pressure\": \"surface_pressure\",\n",
    "    # Upper air variables - U component\n",
    "    \"u_component_of_wind100\": \"wind_u_100hPa\",\n",
    "    \"u_component_of_wind200\": \"wind_u_200hPa\",\n",
    "    \"u_component_of_wind400\": \"wind_u_400hPa\",\n",
    "    \"u_component_of_wind600\": \"wind_u_600hPa\",\n",
    "    \"u_component_of_wind700\": \"wind_u_700hPa\",\n",
    "    \"u_component_of_wind850\": \"wind_u_850hPa\",\n",
    "    \"u_component_of_wind925\": \"wind_u_925hPa\",\n",
    "    \"u_component_of_wind1000\": \"wind_u_1000hPa\",\n",
    "    # Upper air variables - V component\n",
    "    \"v_component_of_wind100\": \"wind_v_100hPa\",\n",
    "    \"v_component_of_wind200\": \"wind_v_200hPa\",\n",
    "    \"v_component_of_wind400\": \"wind_v_400hPa\",\n",
    "    \"v_component_of_wind600\": \"wind_v_600hPa\",\n",
    "    \"v_component_of_wind700\": \"wind_v_700hPa\",\n",
    "    \"v_component_of_wind850\": \"wind_v_850hPa\",\n",
    "    \"v_component_of_wind925\": \"wind_v_925hPa\",\n",
    "    \"v_component_of_wind1000\": \"wind_v_1000hPa\",\n",
    "    # Upper air variables - Temperature\n",
    "    \"temperature100\": \"temperature_100hPa\",\n",
    "    \"temperature200\": \"temperature_200hPa\",\n",
    "    \"temperature400\": \"temperature_400hPa\",\n",
    "    \"temperature600\": \"temperature_600hPa\",\n",
    "    \"temperature700\": \"temperature_700hPa\",\n",
    "    \"temperature850\": \"temperature_850hPa\",\n",
    "    \"temperature925\": \"temperature_925hPa\",\n",
    "    \"temperature1000\": \"temperature_1000hPa\",\n",
    "    # Upper air variables - Vertical velocity\n",
    "    \"vertical_velocity100\": \"vertical_velocity_100hPa\",\n",
    "    \"vertical_velocity200\": \"vertical_velocity_200hPa\",\n",
    "    \"vertical_velocity400\": \"vertical_velocity_400hPa\",\n",
    "    \"vertical_velocity600\": \"vertical_velocity_600hPa\",\n",
    "    \"vertical_velocity700\": \"vertical_velocity_700hPa\",\n",
    "    \"vertical_velocity850\": \"vertical_velocity_850hPa\",\n",
    "    \"vertical_velocity925\": \"vertical_velocity_925hPa\",\n",
    "    \"vertical_velocity1000\": \"vertical_velocity_1000hPa\",\n",
    "    # Upper air variables - Geopotential\n",
    "    \"geopotential100\": \"geopotential_100hPa\",\n",
    "    \"geopotential200\": \"geopotential_200hPa\",\n",
    "    \"geopotential400\": \"geopotential_400hPa\",\n",
    "    \"geopotential600\": \"geopotential_600hPa\",\n",
    "    \"geopotential700\": \"geopotential_700hPa\",\n",
    "    \"geopotential850\": \"geopotential_850hPa\",\n",
    "    \"geopotential925\": \"geopotential_925hPa\",\n",
    "    \"geopotential1000\": \"geopotential_1000hPa\",\n",
    "}\n",
    "\n",
    "\n",
    "# These variables will be used as `basename` for the vertical profiles.\n",
    "# Since the input of the zarr archives is expected to have data vars that are 2D in space\n",
    "# we need some base_name prefix to create the 3D variables\n",
    "VARIABLES_3D = [\n",
    "    \"wind_u\",\n",
    "    \"wind_v\",\n",
    "    \"geopotential\",\n",
    "    \"temperature\",\n",
    "    \"relative_humidity\",\n",
    "    \"vertical_velocity\",\n",
    "]\n",
    "\n",
    "# Add units dictionary after the imports\n",
    "# units from zarr archives are not reliable and should rather be defined here\n",
    "VARIABLE_UNITS = {\n",
    "    # Surface and near-surface variables\n",
    "    \"temperature_2m\": \"K\",\n",
    "    \"wind_u_10m\": \"m/s\",\n",
    "    \"wind_v_10m\": \"m/s\",\n",
    "    \"pressure_sea_level\": \"Pa\",\n",
    "    \"surface_pressure\": \"Pa\",\n",
    "    \"precipitation\": \"mm/h\",\n",
    "    #\"surface_sensible_heat_flux\": \"W/m²\",\n",
    "    \"surface_net_shortwave_radiation\": \"W/m²\",\n",
    "    \"surface_net_longwave_radiation\": \"W/m²\",\n",
    "    # Upper air variables\n",
    "    \"wind_u_level\": \"m/s\",\n",
    "    \"wind_v_level\": \"m/s\",\n",
    "    \"geopotential_level\": \"m²/s²\",\n",
    "    \"temperature_level\": \"K\",\n",
    "    \"relative_humidity_level\": \"%\",\n",
    "    \"vertical_velocity_level\": \"Pa/s\",\n",
    "}\n",
    "\n",
    "# Define Thresholds for the ETS metric (Equitable Threat Score)\n",
    "# These are calculated for wind and precipitation if available\n",
    "# The score creates contingency tables for different thresholds\n",
    "# The ETS is calculated for each threshold and the results are plotted\n",
    "# The default thresholds are [0.1, 1, 5] for precipitation and [2.5, 5, 10] for wind\n",
    "THRESHOLDS_PRECIPITATION = [0.1, 1, 5]  # mm/h\n",
    "THRESHOLDS_WIND = [2.5, 5, 10]  # m/s\n",
    "\n",
    "# Define the metrics to compute for the verification\n",
    "# Some additional verifications will always be computed if the repsective vars\n",
    "# are available in the data\n",
    "METRICS = [\n",
    "    # \"MAE\",\n",
    "    \"RMSE\",\n",
    "    # \"MSE\",\n",
    "    \"ME\",\n",
    "    \"STDEV_ERR\",\n",
    "    \"RelativeMAE\",\n",
    "    # \"RelativeRMSE\",\n",
    "    # \"PearsonR\",\n",
    "    # \"Wasserstein\",\n",
    "]\n",
    "\n",
    "# This setting is relevant for the mapplots in chapter 1\n",
    "# Higher levels of ZOOM will zoom in on the map, cropping the boundary\n",
    "BORDER_WIDTH = 300000 # in m\n",
    "ZOOM = 1  # Unused\n",
    "\n",
    "# For some chapters a random seed is required to reproduce the results\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# The DPI used in all plots in the notebook, export to pdf will always be 300 DPI\n",
    "DPI = 100\n",
    "\n",
    "# Subsample the data for faster plotting, 0.1 refers to 10% of the ml/nwp data\n",
    "# sampled along the start_time, x and y dimensions. If you calculate the FSS\n",
    "# metrics you would want to limit subsampling to the time-dimensions! There is a\n",
    "# trade-off between speed and accuracy, that each user has to find.\n",
    "SUBSAMPLE_FRACTION = 1.0\n",
    "\n",
    "# If the data should be loaded into memory. Makes following calculations faster\n",
    "# but requires enough memory to hold the data.\n",
    "PRECOMPUTE_DATA = False\n",
    "\n",
    "# Subsample the data for FSS threshold calculation, 1e7 refers to the number of elements\n",
    "# This is not critical, as it is only used to calculate the 90% threshold\n",
    "# for the FSS based on the ground truth data\n",
    "SUBSAMPLE_FSS_THRESHOLD = 1e7\n",
    "\n",
    "# Takes a long time, but if you see NaN in your output, you can set this to True\n",
    "# This will check if there are any missing values in the data further below\n",
    "# THIS NOTEBOOK WILL ONLY WORK RELIABLY IF THERE ARE NO MISSING VALUES\n",
    "# If there are missing values, you have to interpolate them or remove them\n",
    "CHECK_MISSING = False\n",
    "\n",
    "# Font sizes for consistent plotting (different fig-sizes wil require different font sizes)\n",
    "FONT_SIZES = {\n",
    "    \"axes\": 24,  # Axis labels and titles\n",
    "    \"ticks\": 24,  # Tick labels\n",
    "    \"legend\": 22,  # Legend text\n",
    "    \"cbar\": 24,  # Colorbar labels\n",
    "    \"suptitle\": 24,  # Figure suptitle\n",
    "    \"title\": 24,  # Axes titles\n",
    "    \"stats\": 22,  # Statistics text in plots\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b2e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for plots and tables\n",
    "Path(\"plots\").mkdir(exist_ok=True)\n",
    "Path(\"tables\").mkdir(exist_ok=True)\n",
    "\n",
    "# Colorblind-friendly color palette\n",
    "COLORS = {\n",
    "    \"gt\": \"#000000\",  # Black\n",
    "    \"ml\": \"#E69F00\",  # Orange\n",
    "    \"nwp\": \"#56B4E9\",  # Light blue\n",
    "    \"error\": \"#CC79A7\",  # Pink\n",
    "}\n",
    "\n",
    "# Line styles and markers for accessibility\n",
    "LINE_STYLES = {\n",
    "    \"gt\": (\"solid\", \"o\"),\n",
    "    \"ml\": (\"dashed\", \"s\"),\n",
    "    \"nwp\": (\"dotted\", \"^\"),\n",
    "}\n",
    "\n",
    "# Set global font sizes\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": FONT_SIZES[\"axes\"],\n",
    "    \"axes.titlesize\": FONT_SIZES[\"axes\"],\n",
    "    \"axes.labelsize\": FONT_SIZES[\"axes\"],\n",
    "    \"xtick.labelsize\": FONT_SIZES[\"ticks\"],\n",
    "    \"ytick.labelsize\": FONT_SIZES[\"ticks\"],\n",
    "    \"legend.fontsize\": FONT_SIZES[\"legend\"],\n",
    "    \"figure.titlesize\": FONT_SIZES[\"suptitle\"],\n",
    "})\n",
    "\n",
    "# Colorblind-friendly colormap for 2D plots\n",
    "COLORMAP = \"viridis\"\n",
    "\n",
    "# First, collect all the base variables and units we need to extend\n",
    "base_level_vars = {}\n",
    "for base_var, unit in VARIABLE_UNITS.items():\n",
    "    if \"_level\" in base_var:\n",
    "        base_level_vars[base_var] = unit\n",
    "\n",
    "# Then create the level-specific entries\n",
    "for level in REQUIRED_LEVELS:\n",
    "    for base_var, unit in base_level_vars.items():\n",
    "        VARIABLE_UNITS[f\"{base_var[:-len('_level')]}_{level}hPa\"] = unit\n",
    "print(f\"All units: {VARIABLE_UNITS}\")\n",
    "\n",
    "\n",
    "def save_plot(fig, name, time=None, remove_title=True, dpi=300):\n",
    "    \"\"\"Helper function to save plots consistently\n",
    "\n",
    "    Args:\n",
    "        fig: matplotlib figure object\n",
    "        name (str): base name for the plot file\n",
    "        time (datetime, optional): timestamp to append to filename\n",
    "        remove_title (bool): remove suptitle/title hierarchically if True\n",
    "        dpi (int): resolution for the saved figure, defaults to 300\n",
    "    \"\"\"\n",
    "    if time is not None:\n",
    "        name = f\"{name}_{time.dt.strftime('%Y%m%d_%H').values}\"\n",
    "\n",
    "    # Sanitize filename by replacing problematic characters\n",
    "    safe_name = name.replace(\"/\", \"_per_\")\n",
    "\n",
    "    # Normalize the path and ensure plots directory exists\n",
    "    plot_dir = Path(\"plots\")\n",
    "    plot_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Remove titles if requested\n",
    "    if remove_title:\n",
    "        if hasattr(fig, \"texts\") and fig.texts:  # Check for suptitle\n",
    "            fig.suptitle(\"\")\n",
    "        ax = fig.gca()\n",
    "        if ax.get_title():\n",
    "            ax.set_title(\"\")\n",
    "\n",
    "    pdf_path = plot_dir / f\"{safe_name}.pdf\"\n",
    "    fig.savefig(pdf_path, bbox_inches=\"tight\", dpi=dpi)\n",
    "\n",
    "\n",
    "def export_table(df, name, caption=\"\"):\n",
    "    \"\"\"Helper function to export tables consistently\"\"\"\n",
    "    # Export to LaTeX with caption\n",
    "    latex_str = df.to_latex(\n",
    "        float_format=\"%.4f\", caption=caption, label=f\"tab:{name}\"\n",
    "    )\n",
    "    with open(f\"tables/{name}.tex\", \"w\") as f:\n",
    "        f.write(latex_str)\n",
    "\n",
    "    # Export to CSV\n",
    "    df.to_csv(f\"tables/{name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ebba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ml = xr.open_zarr(PATH_ML)\n",
    "ds_ml = ds_ml.sel(state_feature=list(VARIABLES_ML.keys()))\n",
    "ds_ml = ds_ml.sel(y=slice(*Y), x=slice(*X))\n",
    "ds_ml = ds_ml.sel(start_time=slice(*START_TIMES))\n",
    "for feature in ds_ml.state_feature.values:\n",
    "    ds_ml[VARIABLES_ML[feature]] = ds_ml[\"state\"].sel(state_feature=feature)\n",
    "forecast_times = (\n",
    "    ds_ml.start_time.values[:, None] + ds_ml.elapsed_forecast_duration.values\n",
    ")\n",
    "ds_ml = ds_ml.assign_coords(\n",
    "    forecast_time=(\n",
    "        (\"start_time\", \"elapsed_forecast_duration\"),\n",
    "        forecast_times,\n",
    "    )\n",
    ")\n",
    "ds_ml = ds_ml.drop_vars([\"state\", \"state_feature\", \"time\"])\n",
    "ds_ml = ds_ml.transpose(\"start_time\", \"elapsed_forecast_duration\", \"x\", \"y\")\n",
    "ds_ml = ds_ml[\n",
    "    [\n",
    "        \"start_time\",\n",
    "        \"elapsed_forecast_duration\",\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        *VARIABLES_ML.values(),\n",
    "    ]\n",
    "]\n",
    "ds_ml = ds_ml.isel(elapsed_forecast_duration=ELAPSED_FORECAST_DURATION)\n",
    "\n",
    "ds_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf42e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_gt = xr.open_zarr(PATH_GROUND_TRUTH)\n",
    "ds_gt = ds_gt.set_index(grid_index=[\"y\", \"x\"]).unstack(\"grid_index\")\n",
    "ds_gt = ds_gt.sel(y=slice(*Y), x=slice(*X))\n",
    "ds_gt = ds_gt.sel(state_feature=list(VARIABLES_ML.keys()))\n",
    "ds_gt = ds_gt.sel(split_name=\"test\").drop_dims([\n",
    "    \"forcing_feature\",\n",
    "    \"static_feature\",\n",
    "    \"split_part\",\n",
    "])\n",
    "for feature in ds_gt.state_feature.values:\n",
    "    ds_gt[VARIABLES_ML[feature]] = ds_gt[\"state\"].sel(state_feature=feature)\n",
    "ds_gt = ds_gt.drop_vars([\n",
    "    \"state\",\n",
    "    \"state_feature\",\n",
    "    \"state_feature_units\",\n",
    "    \"state_feature_long_name\",\n",
    "    \"state_feature_source_dataset\",\n",
    "    \"state__train__diff_mean\",\n",
    "    \"state__train__diff_std\",\n",
    "    \"state__train__mean\",\n",
    "    \"state__train__std\",\n",
    "])\n",
    "ds_gt = ds_gt.transpose(\"time\", \"x\", \"y\")\n",
    "ds_gt = ds_gt[\n",
    "    [\n",
    "        \"time\",\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        *VARIABLES_GROUND_TRUTH.values(),\n",
    "    ]\n",
    "]\n",
    "ds_gt = ds_gt.sel(time=np.unique(ds_ml.forecast_time.values.flatten()))\n",
    "ds_gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fa285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_nwp = xr.open_zarr(PATH_NWP)\n",
    "ds_nwp = ds_nwp.sel(y=slice(*Y), x=slice(*X), analysis_time=slice(*START_TIMES))\n",
    "ds_nwp = ds_nwp[VARIABLES_NWP.keys()].rename(VARIABLES_NWP)\n",
    "ds_nwp = ds_nwp.rename_dims({\n",
    "    \"analysis_time\": \"start_time\",\n",
    "})\n",
    "ds_nwp = ds_nwp.rename_vars({\n",
    "    \"analysis_time\": \"start_time\",\n",
    "})\n",
    "forecast_times = (\n",
    "    ds_nwp.start_time.values[:, None] + ds_nwp.elapsed_forecast_duration.values\n",
    ")\n",
    "ds_nwp = ds_nwp.assign_coords(\n",
    "    forecast_time=(\n",
    "        (\"start_time\", \"elapsed_forecast_duration\"),\n",
    "        forecast_times,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Do not need these, remove so no issues later\n",
    "ds_nwp = ds_nwp.drop([\"time\"])\n",
    "\n",
    "# The NWP data starts at elapsed forecast duration 0 = start_time\n",
    "ds_nwp = ds_nwp.isel(\n",
    "    elapsed_forecast_duration=ELAPSED_FORECAST_DURATION_SHORT\n",
    ")\n",
    "\n",
    "ds_nwp = ds_nwp.transpose(\"start_time\", \"elapsed_forecast_duration\", \"x\", \"y\")\n",
    "ds_nwp = ds_nwp[\n",
    "    [\n",
    "        \"start_time\",\n",
    "        \"elapsed_forecast_duration\",\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        *VARIABLES_NWP.values(),\n",
    "    ]\n",
    "]\n",
    "\n",
    "ds_nwp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46114d2",
   "metadata": {},
   "source": [
    "Check for missing data in any of the variables. If you have missing data, you need to handle it before running the verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648b77c2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if CHECK_MISSING:\n",
    "    missing_counts = dask.compute(\n",
    "        {var: ds_gt[var].isnull().sum().values for var in ds_gt.data_vars},\n",
    "        {var: ds_nwp[var].isnull().sum().values for var in ds_nwp.data_vars},\n",
    "        {var: ds_ml[var].isnull().sum().values for var in ds_ml.data_vars},\n",
    "    )\n",
    "    # Unpack results\n",
    "    gt_missing, nwp_missing, ml_missing = missing_counts\n",
    "\n",
    "    # Print results\n",
    "    print(\"Ground Truth\")\n",
    "    for var, count in gt_missing.items():\n",
    "        print(f\"{var}: {count} missing values\")\n",
    "\n",
    "    print(\"\\nNWP Model\")\n",
    "    for var, count in nwp_missing.items():\n",
    "        print(f\"{var}: {count} missing values\")\n",
    "\n",
    "    print(\"\\nML Model\")\n",
    "    for var, count in ml_missing.items():\n",
    "        print(f\"{var}: {count} missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b36ff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ds_gt.sizes[\"x\"] == ds_ml.sizes[\"x\"]\n",
    "assert ds_gt.sizes[\"x\"] == ds_nwp.sizes[\"x\"]\n",
    "assert ds_gt.sizes[\"y\"] == ds_ml.sizes[\"y\"]\n",
    "assert ds_gt.sizes[\"y\"] == ds_nwp.sizes[\"y\"]\n",
    "assert ds_gt.sizes[\"time\"] == len(\n",
    "    np.unique(ds_ml.forecast_time.values.flatten())\n",
    ")\n",
    "# Since nwp has less lead times below might not hold\n",
    "#assert ds_gt.sizes[\"time\"] == len(\n",
    "#    np.unique(ds_nwp.forecast_time.values.flatten())\n",
    "#)\n",
    "\n",
    "# Generate random indices for each dimension\n",
    "rng = np.random.RandomState(RANDOM_SEED)\n",
    "sampled_start_time_indices = np.sort(\n",
    "    rng.choice(\n",
    "        len(ds_ml.start_time),\n",
    "        size=int(len(ds_ml.start_time) * SUBSAMPLE_FRACTION),\n",
    "        replace=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "# with (\n",
    "#     LocalCluster(\n",
    "#         n_workers=4,\n",
    "#         threads_per_worker=16,\n",
    "#         memory_limit=\"96GB\",\n",
    "#         local_directory=\"/iopsstor/scratch/cscs/sadamov\",  # Use fast local storage for spilling\n",
    "#         dashboard_address=None,\n",
    "#     ) as cluster\n",
    "# ):\n",
    "#     with Client(cluster) as client:\n",
    "ds_ml_sampled = ds_ml.isel(start_time=sampled_start_time_indices)\n",
    "ds_nwp_sampled = ds_nwp.isel(start_time=sampled_start_time_indices)\n",
    "ds_gt_sampled = ds_gt.sel(time=ds_ml_sampled.forecast_time)\n",
    "if PRECOMPUTE_DATA:\n",
    "    with ProgressBar():\n",
    "        print(\"Computing ML data\")\n",
    "        ds_ml_sampled = ds_ml_sampled.compute()\n",
    "        print(\"Computing NWP data\")\n",
    "        ds_nwp_sampled = ds_nwp_sampled.compute()\n",
    "        print(\"Computing GT data\")\n",
    "        ds_gt_sampled = ds_gt_sampled.compute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d1d0ba",
   "metadata": {},
   "source": [
    "### 4. Energy Spectra\n",
    "\n",
    "This chapter examines how energy is distributed across different spatial scales\n",
    "in the atmosphere by computing and comparing the energy spectra of both models.\n",
    "This analysis is critical in understanding the models' capabilities to simulate\n",
    "atmospheric processes ranging from large-scale weather systems to small-scale\n",
    "turbulence.\n",
    "\n",
    "**FFT Computation:** The Fast Fourier Transform (FFT) is used to transform spatial data into the frequency domain, revealing how different scales contribute to the overall energy. The energy spectra are averaged over latitudes.\n",
    "\n",
    "**Scale Representation:** The energy spectra show whether the ML model captures the correct amount of energy at various spatial scales.\n",
    "\n",
    "**Effective Resolution:** Identifying the effective resolution helps understand the smallest scales that the model can reliably simulate.\n",
    "\n",
    "**Numerical Artifacts:** Limitations in numerical precision can introduce artifacts in the spectra, especially at the smallest scales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11ebd3c",
   "metadata": {},
   "source": [
    "To interpret the Log-Spectral Distance (LSD) metric:\n",
    "The LSD quantifies the difference between two spectra, with lower values indicating better similarity (area between the two spectra). \n",
    "\n",
    "Lower values indicate better similarity between spectra\n",
    "- LSD = 0 means identical spectra\n",
    "\n",
    "Typical values depend on the specific application, but generally:\n",
    "- LSD < 1: Good similarity\n",
    "- 1 < LSD < 2: Moderate differences\n",
    "- LSD > 2: Significant differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c9c0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_energy_spectra(data):\n",
    "    \"\"\"Calculate the energy spectra of the given data using 2D FFT.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : xarray.DataArray\n",
    "        The data for which the energy spectra should be calculated.\n",
    "        Expected dimensions must include 'x' and 'y', other dimensions will be handled automatically.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    wavenumber : np.ndarray\n",
    "        The isotropic wavenumbers.\n",
    "    power : np.ndarray\n",
    "        The power spectrum averaged over all non-spatial dimensions.\n",
    "    effective_resolution : float\n",
    "        The effective resolution of the model.\n",
    "    \"\"\"\n",
    "    # Get grid spacing in meters\n",
    "    dx = abs(float(data.x[1] - data.x[0]))\n",
    "    dy = abs(float(data.y[1] - data.y[0]))\n",
    "\n",
    "    # Identify spatial dimensions\n",
    "    spatial_dims = [\"y\", \"x\"]\n",
    "\n",
    "    # Move spatial dimensions to the end\n",
    "    other_dims = [dim for dim in data.dims if dim not in spatial_dims]\n",
    "    var_data = data.transpose(*other_dims, *spatial_dims).values\n",
    "\n",
    "    # Reshape the array to combine all non-spatial dimensions\n",
    "    shape = var_data.shape\n",
    "    ny, nx = shape[-2:]\n",
    "\n",
    "    if len(shape) > 2:\n",
    "        var_data = var_data.reshape(-1, ny, nx)\n",
    "    else:\n",
    "        var_data = var_data[np.newaxis, :, :]\n",
    "\n",
    "    # Compute 2D FFT\n",
    "    fft_data = np.fft.fft2(var_data, axes=(-2, -1))\n",
    "    power_spectrum = (np.abs(fft_data) ** 2).mean(axis=0)\n",
    "\n",
    "    # Rest of the function remains the same\n",
    "    # Get wavenumbers\n",
    "    kx = np.fft.fftfreq(nx, d=dx)\n",
    "    ky = np.fft.fftfreq(ny, d=dy)\n",
    "\n",
    "    # Create 2D wavenumber grid\n",
    "    kxx, kyy = np.meshgrid(kx, ky)\n",
    "    k_mag = np.sqrt(kxx**2 + kyy**2)\n",
    "\n",
    "    # Create wavenumber bins for azimuthal averaging\n",
    "    k_bins = np.logspace(\n",
    "        np.log10(k_mag[k_mag > 0].min()), np.log10(k_mag.max()), num=50\n",
    "    )\n",
    "\n",
    "    # Perform azimuthal averaging\n",
    "    k_averaged = []\n",
    "    power_averaged = []\n",
    "\n",
    "    for i in range(len(k_bins) - 1):\n",
    "        k_mask = (k_mag >= k_bins[i]) & (k_mag < k_bins[i + 1])\n",
    "        if k_mask.any():\n",
    "            k_averaged.append(np.mean(k_mag[k_mask]))\n",
    "            power_averaged.append(np.mean(power_spectrum[k_mask]))\n",
    "\n",
    "    # Convert to arrays\n",
    "    k_averaged = np.array(k_averaged)\n",
    "    power_averaged = np.array(power_averaged)\n",
    "\n",
    "    # Calculate effective resolution\n",
    "    effective_resolution = 1 / (4 * dx)\n",
    "\n",
    "    # Remove first and last two wavenumbers\n",
    "    return k_averaged[2:-2], power_averaged[2:-2], effective_resolution\n",
    "\n",
    "\n",
    "def calculate_all_spectra(ds_gt, ds_ml, ds_nwp, variables):\n",
    "    \"\"\"Calculate and cache all energy spectra, including temporal evolution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds_gt : xarray.Dataset\n",
    "        Ground truth dataset\n",
    "    ds_ml : xarray.Dataset\n",
    "        Machine learning model dataset\n",
    "    ds_nwp : xarray.Dataset\n",
    "        Numerical weather prediction model dataset\n",
    "    variables : list\n",
    "        List of variables to process\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Nested dictionary containing wavenumbers, spectra and effective resolution\n",
    "        for each dataset and variable, including temporal evolution\n",
    "    \"\"\"\n",
    "    spectra_cache = {\n",
    "        \"gt\": {},\n",
    "        \"ml\": {\"static\": {}, \"temporal\": {}},\n",
    "        \"nwp\": {\"static\": {}, \"temporal\": {}} if ds_nwp is not None else None,\n",
    "    }\n",
    "\n",
    "    for var in variables:\n",
    "        if var not in ds_gt or var not in ds_ml:\n",
    "            continue\n",
    "        print(f\"Calculating spectra for {var}...\")\n",
    "\n",
    "        # Calculate static spectra for ground truth\n",
    "        k_gt, spec_gt, eff_res = calculate_energy_spectra(ds_gt[var])\n",
    "        spectra_cache[\"gt\"][var] = (k_gt, spec_gt, eff_res)\n",
    "\n",
    "        # Calculate temporal spectra for ML model\n",
    "        forecast_times = ds_ml.elapsed_forecast_duration.values\n",
    "        ml_temporal = {}\n",
    "        for time in forecast_times:\n",
    "            data = ds_ml[var].sel(elapsed_forecast_duration=time)\n",
    "            k, spec, _ = calculate_energy_spectra(data)\n",
    "            ml_temporal[time] = (k, spec)\n",
    "\n",
    "        spectra_cache[\"ml\"][\"temporal\"][var] = ml_temporal\n",
    "        spectra_cache[\"ml\"][\"static\"][var] = calculate_energy_spectra(\n",
    "            ds_ml[var]\n",
    "        )\n",
    "\n",
    "        # Calculate temporal spectra for NWP model if available\n",
    "        if ds_nwp is not None and var in ds_nwp:\n",
    "            forecast_times_nwp = ds_nwp.elapsed_forecast_duration.values\n",
    "            nwp_temporal = {}\n",
    "            for time in forecast_times_nwp:\n",
    "                data = ds_nwp[var].sel(elapsed_forecast_duration=time)\n",
    "                k, spec, _ = calculate_energy_spectra(data)\n",
    "                nwp_temporal[time] = (k, spec)\n",
    "\n",
    "            spectra_cache[\"nwp\"][\"temporal\"][var] = nwp_temporal\n",
    "            spectra_cache[\"nwp\"][\"static\"][var] = calculate_energy_spectra(\n",
    "                ds_nwp[var]\n",
    "            )\n",
    "\n",
    "    return spectra_cache\n",
    "\n",
    "\n",
    "def plot_energy_spectra(spectra_cache, var, level=None, show_legend=False):\n",
    "    \"\"\"Plot energy spectra comparison using pre-calculated spectra.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spectra_cache : dict\n",
    "        Cache containing pre-calculated spectra\n",
    "    var : str\n",
    "        Variable name to plot\n",
    "    level : float, optional\n",
    "        Vertical level in hPa\n",
    "    show_legend : bool, optional\n",
    "        Whether to show the legend (default: False)\n",
    "    \"\"\"\n",
    "    k_gt, spec_gt, eff_res = spectra_cache[\"gt\"][var]\n",
    "    k_ml, spec_ml, _ = spectra_cache[\"ml\"][\"static\"][var]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(11, 6.5), dpi=DPI)\n",
    "\n",
    "    # Plot ground truth spectrum\n",
    "    ax.loglog(\n",
    "        k_gt,\n",
    "        spec_gt,\n",
    "        color=COLORS[\"gt\"],\n",
    "        label=\"Ground Truth\",\n",
    "        linestyle=LINE_STYLES[\"gt\"][0],\n",
    "        marker=LINE_STYLES[\"gt\"][1],\n",
    "        markevery=5,\n",
    "    )\n",
    "\n",
    "    # Plot NWP spectrum if available\n",
    "    if spectra_cache[\"nwp\"] and var in spectra_cache[\"nwp\"][\"static\"]:\n",
    "        k_nwp, spec_nwp, _ = spectra_cache[\"nwp\"][\"static\"][var]\n",
    "        ax.loglog(\n",
    "            k_nwp,\n",
    "            spec_nwp,\n",
    "            color=COLORS[\"nwp\"],\n",
    "            label=\"NWP Model Prediction\",\n",
    "            linestyle=LINE_STYLES[\"nwp\"][0],\n",
    "            marker=LINE_STYLES[\"nwp\"][1],\n",
    "            markevery=3,\n",
    "        )\n",
    "\n",
    "    # Plot ML spectrum\n",
    "    ax.loglog(\n",
    "        k_ml,\n",
    "        spec_ml,\n",
    "        color=COLORS[\"ml\"],\n",
    "        label=\"ML Model Prediction\",\n",
    "        linestyle=LINE_STYLES[\"ml\"][0],\n",
    "        marker=LINE_STYLES[\"ml\"][1],\n",
    "        markevery=4,\n",
    "    )\n",
    "\n",
    "    # Plot effective resolution\n",
    "    ax.axvline(\n",
    "        eff_res,\n",
    "        color=\"salmon\",\n",
    "        linestyle=\"--\",\n",
    "        label=\"Effective Model Resolution\",\n",
    "    )\n",
    "\n",
    "    # Add LSD metric\n",
    "    spec_nwp = (\n",
    "        spectra_cache[\"nwp\"][\"static\"][var][1]\n",
    "        if spectra_cache[\"nwp\"] and var in spectra_cache[\"nwp\"][\"static\"]\n",
    "        else None\n",
    "    )\n",
    "    add_lsd_to_plot(ax, spec_gt, spec_ml, spec_nwp)\n",
    "\n",
    "    # Customize plot\n",
    "    ax.set_xlabel(\"Wavenumber (1/m)\")\n",
    "    unit = VARIABLE_UNITS.get(var, \"\")\n",
    "    ax.set_ylabel(f\"Energy Density (({unit})² * m)\")\n",
    "    title = f\"Energy Spectra Comparison for {var}\"\n",
    "    if level is not None:\n",
    "        title += f\" at Level {level} hPa\"\n",
    "    ax.set_title(title)\n",
    "    if show_legend:\n",
    "        ax.legend(loc='upper right')\n",
    "    ax.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "\n",
    "    # Save and display plot\n",
    "    plot_name = f\"energy_spectra_{var}\"\n",
    "    if level is not None:\n",
    "        plot_name += f\"_level_{level}\"\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    save_plot(fig, plot_name)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def display_lsd_table(spectra_cache, variables, name, caption=\"\"):\n",
    "    \"\"\"Display and export LSD metrics table using pre-calculated spectra.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spectra_cache : dict\n",
    "        Cache containing pre-calculated spectra\n",
    "    variables : list\n",
    "        List of variables to analyze\n",
    "    name : str\n",
    "        Name for exported files\n",
    "    caption : str, optional\n",
    "        Caption for LaTeX table\n",
    "    \"\"\"\n",
    "    lsd_data = {var: {\"ML\": None, \"NWP\": None} for var in variables}\n",
    "\n",
    "    for var in variables:\n",
    "        if (\n",
    "            var not in spectra_cache[\"gt\"]\n",
    "            or var not in spectra_cache[\"ml\"][\"static\"]\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        spec_gt = spectra_cache[\"gt\"][var][1]\n",
    "        spec_ml = spectra_cache[\"ml\"][\"static\"][var][1]\n",
    "        spec_nwp = (\n",
    "            spectra_cache[\"nwp\"][\"static\"][var][1]\n",
    "            if spectra_cache[\"nwp\"] and var in spectra_cache[\"nwp\"][\"static\"]\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        lsd_ml, lsd_nwp = calculate_log_spectral_distance(\n",
    "            spec_gt, spec_ml, spec_nwp\n",
    "        )\n",
    "        lsd_data[var][\"ML\"] = lsd_ml\n",
    "        if lsd_nwp is not None:\n",
    "            lsd_data[var][\"NWP\"] = lsd_nwp\n",
    "\n",
    "    df = pd.DataFrame(lsd_data).T\n",
    "\n",
    "    # Display styled table\n",
    "    styled_df = df.style.format(\n",
    "        lambda x: f\"{x:.3f}\" if pd.notnull(x) else \"-\"\n",
    "    ).map(\n",
    "        lambda x: f\"color: {'green' if x < 1 else 'orange' if x < 2 else 'red'}\"\n",
    "        if pd.notnull(x)\n",
    "        else \"\"\n",
    "    )\n",
    "    display(styled_df)\n",
    "\n",
    "    # Export raw dataframe\n",
    "    export_table(df, name, caption)\n",
    "\n",
    "\n",
    "def plot_wavenumber_evolution(\n",
    "    spectra_cache,\n",
    "    ds_ml,\n",
    "    ds_nwp,\n",
    "    variables,\n",
    "    wavenumbers=[1e-2, 5e-2, 1e-1],\n",
    "    level=None,\n",
    "):\n",
    "    \"\"\"Plot wavenumber evolution using pre-calculated temporal spectra.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spectra_cache : dict\n",
    "        Cache containing pre-calculated spectra including temporal evolution\n",
    "    ds_ml : xarray.Dataset\n",
    "        Machine learning model dataset (used only for time coordinates)\n",
    "    ds_nwp : xarray.Dataset\n",
    "        Numerical weather prediction model dataset\n",
    "    variables : list\n",
    "        List of variables to analyze\n",
    "    wavenumbers : list, optional\n",
    "        List of wavenumbers to analyze\n",
    "    level : float, optional\n",
    "        Vertical level in hPa\n",
    "    \"\"\"\n",
    "    forecast_times = ds_ml.elapsed_forecast_duration.values\n",
    "\n",
    "    for var in variables:\n",
    "        if (\n",
    "            var not in spectra_cache[\"gt\"]\n",
    "            or var not in spectra_cache[\"ml\"][\"temporal\"]\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        fig, axes = plt.subplots(1, len(wavenumbers), figsize=(24, 8), dpi=DPI)\n",
    "\n",
    "        for idx, target_k in enumerate(wavenumbers):\n",
    "            spectra = {\n",
    "                \"gt\": [],\n",
    "                \"ml\": [],\n",
    "                \"nwp\": [] if spectra_cache[\"nwp\"] else None,\n",
    "            }\n",
    "\n",
    "            # Get ground truth power for target wavenumber\n",
    "            k_gt, spec_gt, _ = spectra_cache[\"gt\"][var]\n",
    "            idx_k_gt = np.abs(k_gt - target_k).argmin()\n",
    "            gt_power = spec_gt[idx_k_gt]\n",
    "\n",
    "            for time in forecast_times:\n",
    "                # Get ML spectra from cache\n",
    "                k_ml, spec_ml = spectra_cache[\"ml\"][\"temporal\"][var][time]\n",
    "                idx_k_ml = np.abs(k_ml - target_k).argmin()\n",
    "                spectra[\"ml\"].append(spec_ml[idx_k_ml])\n",
    "\n",
    "                # Get NWP spectra from cache if available\n",
    "                if (\n",
    "                    spectra_cache[\"nwp\"]\n",
    "                    and var in spectra_cache[\"nwp\"][\"temporal\"]\n",
    "                    and time in spectra_cache[\"nwp\"][\"temporal\"][var]\n",
    "                ):\n",
    "                    k_nwp, spec_nwp = spectra_cache[\"nwp\"][\"temporal\"][var][\n",
    "                        time\n",
    "                    ]\n",
    "                    idx_k_nwp = np.abs(k_nwp - target_k).argmin()\n",
    "                    spectra[\"nwp\"].append(spec_nwp[idx_k_nwp])\n",
    "                else:\n",
    "                    spectra[\"nwp\"].append(np.nan)\n",
    "\n",
    "\n",
    "                spectra[\"gt\"].append(gt_power)\n",
    "\n",
    "            # Plot evolution for current wavenumber\n",
    "            hours = forecast_times / np.timedelta64(1, \"h\")\n",
    "\n",
    "            # Export table\n",
    "            export_table(\n",
    "                pd.DataFrame(\n",
    "                    {\n",
    "                        key.upper(): values\n",
    "                        for key, values in spectra.items()\n",
    "                        if values\n",
    "                    },\n",
    "                    index=hours,\n",
    "                ).rename_axis(\n",
    "                    index=\"Elapsed Forecast Duration (h)\",\n",
    "                    columns=f\"Energy Density (k={target_k:.2e})\",\n",
    "                ),\n",
    "                f\"wavenumber_evolution_{var}_k{target_k:.2e}\",\n",
    "            )\n",
    "\n",
    "            # Plot spectra\n",
    "            for key, values in spectra.items():\n",
    "                if not values:\n",
    "                    continue\n",
    "                \n",
    "                if not np.isnan(values).all():\n",
    "                    axes[idx].plot(\n",
    "                        hours,\n",
    "                        values,\n",
    "                        color=COLORS[key],\n",
    "                        linestyle=LINE_STYLES[key][0],\n",
    "                        marker=LINE_STYLES[key][1],\n",
    "                        label=key.upper(),\n",
    "                    )\n",
    "\n",
    "            # Add titles and labels\n",
    "            axes[idx].set_title(f\"k = {target_k:.2f}\")\n",
    "            if idx == len(wavenumbers) // 2:  # Only middle plot gets x-label\n",
    "                axes[idx].set_xlabel(\"Elapsed Forecast Duration (h)\")\n",
    "            if idx == 0:\n",
    "                axes[idx].set_ylabel(\"Energy Density\")\n",
    "                axes[idx].legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        save_plot(fig, f\"wavenumber_evolution_{var}\", remove_title=False)\n",
    "\n",
    "\n",
    "def calculate_log_spectral_distance(true_spectrum, ml_spectrum, nwp_spectrum):\n",
    "    \"\"\"\n",
    "    Calculate the Log Spectral Distance between three power spectra\n",
    "    \"\"\"\n",
    "    eps = 1e-10\n",
    "    log_spec1 = np.log10(true_spectrum + eps)\n",
    "    log_spec2 = np.log10(ml_spectrum + eps)\n",
    "    lsd_ml = np.sqrt(np.mean((log_spec1 - log_spec2) ** 2))\n",
    "    if nwp_spectrum is None:\n",
    "        return lsd_ml, None\n",
    "    log_spec3 = np.log10(nwp_spectrum + eps)\n",
    "    lsd_nwp = np.sqrt(np.mean((log_spec1 - log_spec3) ** 2))\n",
    "    return lsd_ml, lsd_nwp\n",
    "\n",
    "\n",
    "def add_lsd_to_plot(ax, true_spectrum, ml_spectrum, nwp_spectrum):\n",
    "    \"\"\"\n",
    "    Add LSD metric as text box to spectrum plot\n",
    "    \"\"\"\n",
    "    if nwp_spectrum is None:\n",
    "        lsd_nwp = None\n",
    "        lsd_ml, _ = calculate_log_spectral_distance(\n",
    "            true_spectrum, ml_spectrum, None\n",
    "        )\n",
    "        textstr = f\"LSD ML = {lsd_ml:.4f}\"\n",
    "    else:\n",
    "        lsd_ml, lsd_nwp = calculate_log_spectral_distance(\n",
    "            true_spectrum, ml_spectrum, nwp_spectrum\n",
    "        )\n",
    "        textstr = f\"LSD NWP = {lsd_nwp:.4f}, LSD ML = {lsd_ml:.4f}\"\n",
    "    props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "    ax.text(\n",
    "        0.05,\n",
    "        0.1,\n",
    "        textstr,\n",
    "        transform=ax.transAxes,\n",
    "        verticalalignment=\"top\",\n",
    "        bbox=props,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67bd698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate all spectra once and cache them\n",
    "spectra_cache_short = calculate_all_spectra(\n",
    "    ds_gt_sampled, \n",
    "    ds_ml_sampled.isel(elapsed_forecast_duration=ELAPSED_FORECAST_DURATION_SHORT), \n",
    "    ds_nwp_sampled.isel(elapsed_forecast_duration=ELAPSED_FORECAST_DURATION_SHORT), \n",
    "    VARIABLES_GROUND_TRUTH.values()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11d2e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot energy spectra for all variables\n",
    "for i, var in enumerate(VARIABLES_GROUND_TRUTH.values()):\n",
    "    plot_energy_spectra(spectra_cache_short, var, show_legend=(i == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a93486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and export LSD metrics table\n",
    "display_lsd_table(\n",
    "    spectra_cache_short,\n",
    "    VARIABLES_GROUND_TRUTH.values(),\n",
    "    name=\"lsd_metrics\",\n",
    "    caption=\"Log Spectral Distance (LSD) metrics comparison between ML and NWP models\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9de5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-compute to get all lead times for ML model\n",
    "spectra_cache = calculate_all_spectra(\n",
    "    ds_gt_sampled, \n",
    "    ds_ml_sampled,\n",
    "    ds_nwp_sampled,\n",
    "    VARIABLES_GROUND_TRUTH.values()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9cec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot wavenumber evolution\n",
    "plot_wavenumber_evolution(\n",
    "    spectra_cache, ds_ml, ds_nwp, variables=VARIABLES_GROUND_TRUTH.values()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a432843",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
